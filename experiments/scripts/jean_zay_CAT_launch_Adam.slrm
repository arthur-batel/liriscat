#!/bin/bash
#SBATCH --job-name=CAT_launch_algebra_IMPACT_Adam
#SBATCH --output=logs/%x_%A_%a.out  # %x=job-name, %A=array master ID, %a=task ID
#SBATCH --error=logs/%x_%A_%a.err
##SBATCH --constraint=v100-16g
#SBATCH --nodes=1
#SBATCH --ntasks=1                  # one task per array element
#SBATCH --gpus-per-task=1           # one GPU each
#SBATCH --cpus-per-task=8
#SBATCH --array=0-4                 # 5 folds: 0,1,2,3,4
#SBATCH --time=01:00:00
#SBATCH --account=enh@v100
#SBATCH --qos=qos_gpu-dev

module purge
module load pytorch-gpu/py3/2.7.0

# ensure the logs directory exists
mkdir -p "${SLURM_SUBMIT_DIR}/logs"

# SLURM_ARRAY_TASK_ID is 0â€“4
srun python CAT_launch_parallel_Adam-SLURM.py algebra --cdm impact --i_fold $SLURM_ARRAY_TASK_ID
