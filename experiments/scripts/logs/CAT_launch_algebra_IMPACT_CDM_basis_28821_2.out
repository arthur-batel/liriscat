PID 1873246 sees CUDA_VISIBLE_DEVICES = 0
→ torch.device is 0 Tesla V100-SXM2-16GB
[INFO 50:11] Using device: cuda
[INFO 50:11] #### config : {'seed': 0, 'dataset_name': 'algebra', 'load_params': True, 'save_params': False, 'embs_path': '../embs/', 'params_path': '../ckpt/', 'early_stopping': True, 'esc': 'error', 'verbose_early_stopping': False, 'disable_tqdm': False, 'valid_metric': 'rmse', 'learning_rate': 0.001, 'batch_size': 512, 'valid_batch_size': 10000, 'num_epochs': 100, 'eval_freq': 1, 'patience': 20, 'device': device(type='cuda'), 'lambda': 2.67605964593852e-06, 'tensorboard': False, 'flush_freq': True, 'pred_metrics': ['mi_acc', 'rmse', 'mae', 'mi_prec', 'mi_rec', 'mi_f_b', 'mi_auc', 'ma_prec', 'ma_rec', 'ma_f_b'], 'profile_metrics': ['meta_doa', 'pc-er', 'rm'], 'num_responses': 12, 'low_mem': False, 'n_query': 25, 'CDM': 'impact', 'i_fold': 2, 'num_inner_users_epochs': 9, 'num_inner_epochs': 10, 'inner_lr': 0.0001, 'inner_user_lr': 0.009, 'meta_lr': 0.05, 'meta_trainer': 'Adam', 'num_workers': 0, 'pin_memory': False, 'debug': False} ####
[INFO 50:38] Random_cont_model
[INFO 50:39] compiling CDM model
[INFO 50:44] compiling selection model
[INFO 50:44] ⏳ Début de l'entraînement...
[INFO 50:44] ✅ Entraînement terminé en 0.00 secondes.
[INFO 50:44] train on cuda
Meta_loss tensor(0.7290, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7274, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7259, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7245, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7233, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7222, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7212, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7203, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7195, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7187, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7180, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7174, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7169, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7164, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7160, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7157, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7154, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7152, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7150, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7149, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7148, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7147, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7147, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7147, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7148, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7148, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7150, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7151, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7154, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7156, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7159, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7162, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7165, device='cuda:0', grad_fn=<DotBackward0>)
Meta_loss tensor(0.7169, device='cuda:0', grad_fn=<DotBackward0>)
---------- best_epoch : 22 ;   
[WARNING 50:56] Computing RM on meta and QUERY set
[INFO 50:59] RM: 0.12275054810599322
[INFO 50:59] Fold 2; results: ({'mi_acc': 0.7629133462905884, 'rmse': 0.4869154691696167, 'mae': 0.23708666861057281, 'mi_prec': 0.8860294222831726, 'mi_rec': 0.799557626247406, 'mi_f_b': 0.8405755162239075, 'mi_auc': 0.7156204063867819, 'ma_prec': 0.6770572662353516, 'ma_rec': 0.7156203985214233, 'ma_f_b': 0.6891457438468933}, {'meta_doa': np.float64(0.518131846536881), 'pc-er': 0.06854248046875, 'rm': 0.12275054810599322})
