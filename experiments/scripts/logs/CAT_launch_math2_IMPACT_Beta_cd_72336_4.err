Loading pytorch-gpu/py3/2.7.0
  Loading requirement: gcc/11.4.1 cuda/12.6.3 nccl/2.25.1-1-cuda
    cudnn/9.5.1.17-cuda openmpi/4.1.6-cuda intel-mkl/2020.4 magma/2.9.0-cuda
    sox/14.4.2 hdf5/1.12.0-mpi-cuda libjpeg-turbo/2.1.3 ffmpeg/6.1.1
    openjdk/11.0.2
/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/selectionStrategy/random.py:30: UserWarning: get_params() Notimplemented
  warnings.warn('get_params() Notimplemented')
  0%|                                                                                                                                                                                                                                    | 0/100 [00:00<?, ?it/s]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  1%|██▏                                                                                                                                                                                                                      | 1/100 [03:42<6:07:51, 222.94s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  2%|████▎                                                                                                                                                                                                                    | 2/100 [07:24<6:02:28, 221.92s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  3%|██████▌                                                                                                                                                                                                                  | 3/100 [11:09<6:01:20, 223.51s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  4%|████████▋                                                                                                                                                                                                                | 4/100 [15:15<6:12:03, 232.54s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  5%|██████████▊                                                                                                                                                                                                              | 5/100 [19:21<6:15:43, 237.30s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  6%|█████████████                                                                                                                                                                                                            | 6/100 [23:25<6:15:29, 239.67s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  7%|███████████████▏                                                                                                                                                                                                         | 7/100 [27:29<6:13:40, 241.08s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  8%|█████████████████▎                                                                                                                                                                                                       | 8/100 [31:28<6:08:25, 240.28s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  9%|███████████████████▌                                                                                                                                                                                                     | 9/100 [35:26<6:03:22, 239.59s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 10%|█████████████████████▌                                                                                                                                                                                                  | 10/100 [39:19<5:56:06, 237.41s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 11%|███████████████████████▊                                                                                                                                                                                                | 11/100 [42:56<5:42:53, 231.17s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 12%|█████████████████████████▉                                                                                                                                                                                              | 12/100 [46:32<5:32:13, 226.52s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 13%|████████████████████████████                                                                                                                                                                                            | 13/100 [50:08<5:24:16, 223.64s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 14%|██████████████████████████████▏                                                                                                                                                                                         | 14/100 [53:45<5:17:26, 221.47s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 15%|████████████████████████████████▍                                                                                                                                                                                       | 15/100 [57:21<5:11:32, 219.91s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 16%|██████████████████████████████████▏                                                                                                                                                                                   | 16/100 [1:00:58<5:06:43, 219.09s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 17%|████████████████████████████████████▍                                                                                                                                                                                 | 17/100 [1:04:35<5:02:06, 218.40s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 18%|██████████████████████████████████████▌                                                                                                                                                                               | 18/100 [1:08:13<4:58:07, 218.14s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 19%|████████████████████████████████████████▋                                                                                                                                                                             | 19/100 [1:11:50<4:54:04, 217.84s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 20%|██████████████████████████████████████████▊                                                                                                                                                                           | 20/100 [1:15:26<4:49:38, 217.23s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 21%|████████████████████████████████████████████▉                                                                                                                                                                         | 21/100 [1:19:02<4:45:38, 216.95s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 22%|███████████████████████████████████████████████                                                                                                                                                                       | 22/100 [1:22:38<4:41:50, 216.81s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 23%|█████████████████████████████████████████████████▏                                                                                                                                                                    | 23/100 [1:26:15<4:38:05, 216.70s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 24%|███████████████████████████████████████████████████▎                                                                                                                                                                  | 24/100 [1:29:51<4:34:22, 216.61s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 25%|█████████████████████████████████████████████████████▌                                                                                                                                                                | 25/100 [1:33:28<4:30:56, 216.75s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 26%|███████████████████████████████████████████████████████▋                                                                                                                                                              | 26/100 [1:37:05<4:27:10, 216.63s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 27%|█████████████████████████████████████████████████████████▊                                                                                                                                                            | 27/100 [1:40:42<4:23:43, 216.75s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 28%|███████████████████████████████████████████████████████████▉                                                                                                                                                          | 28/100 [1:44:18<4:20:03, 216.72s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 29%|██████████████████████████████████████████████████████████████                                                                                                                                                        | 29/100 [1:47:55<4:16:29, 216.75s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 30%|████████████████████████████████████████████████████████████████▏                                                                                                                                                     | 30/100 [1:51:32<4:12:44, 216.63s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 31%|██████████████████████████████████████████████████████████████████▎                                                                                                                                                   | 31/100 [1:55:09<4:09:17, 216.77s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 32%|████████████████████████████████████████████████████████████████████▍                                                                                                                                                 | 32/100 [1:58:46<4:05:44, 216.83s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 33%|██████████████████████████████████████████████████████████████████████▌                                                                                                                                               | 33/100 [2:02:22<4:02:03, 216.76s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 34%|████████████████████████████████████████████████████████████████████████▊                                                                                                                                             | 34/100 [2:05:59<3:58:31, 216.85s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 35%|██████████████████████████████████████████████████████████████████████████▉                                                                                                                                           | 35/100 [2:09:35<3:54:40, 216.62s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 36%|█████████████████████████████████████████████████████████████████████████████                                                                                                                                         | 36/100 [2:13:13<3:51:14, 216.80s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 37%|███████████████████████████████████████████████████████████████████████████████▏                                                                                                                                      | 37/100 [2:16:49<3:47:21, 216.54s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 38%|█████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                    | 38/100 [2:20:24<3:43:30, 216.31s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 39%|███████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                  | 39/100 [2:24:01<3:40:00, 216.40s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 40%|█████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                | 40/100 [2:27:37<3:36:14, 216.24s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 40%|█████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                | 40/100 [2:31:13<3:46:50, 226.84s/it]
  0%|                                                                                                                                                                                                                                     | 0/16 [00:00<?, ?it/s]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  6%|█████████████▊                                                                                                                                                                                                               | 1/16 [00:00<00:06,  2.33it/s] 12%|███████████████████████████▋                                                                                                                                                                                                 | 2/16 [00:01<00:10,  1.36it/s] 19%|█████████████████████████████████████████▍                                                                                                                                                                                   | 3/16 [00:02<00:11,  1.13it/s] 25%|███████████████████████████████████████████████████████▎                                                                                                                                                                     | 4/16 [00:04<00:14,  1.17s/it] 31%|█████████████████████████████████████████████████████████████████████                                                                                                                                                        | 5/16 [00:06<00:16,  1.49s/it] 38%|██████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                          | 6/16 [00:08<00:17,  1.78s/it] 44%|████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                            | 7/16 [00:11<00:18,  2.07s/it] 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                              | 8/16 [00:14<00:18,  2.37s/it] 56%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                | 9/16 [00:17<00:19,  2.73s/it] 62%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                  | 10/16 [00:21<00:18,  3.11s/it] 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                    | 11/16 [00:25<00:17,  3.47s/it] 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                       | 12/16 [00:30<00:15,  3.81s/it] 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                         | 13/16 [00:35<00:12,  4.15s/it] 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                           | 14/16 [00:40<00:09,  4.57s/it] 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎             | 15/16 [00:46<00:04,  4.90s/it]100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:52<00:00,  5.29s/it]100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:52<00:00,  3.30s/it]
