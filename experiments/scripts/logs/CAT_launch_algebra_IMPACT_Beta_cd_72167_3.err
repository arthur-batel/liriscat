Loading pytorch-gpu/py3/2.7.0
  Loading requirement: gcc/11.4.1 cuda/12.6.3 nccl/2.25.1-1-cuda
    cudnn/9.5.1.17-cuda openmpi/4.1.6-cuda intel-mkl/2020.4 magma/2.9.0-cuda
    sox/14.4.2 hdf5/1.12.0-mpi-cuda libjpeg-turbo/2.1.3 ffmpeg/6.1.1
    openjdk/11.0.2
/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/selectionStrategy/random.py:30: UserWarning: get_params() Notimplemented
  warnings.warn('get_params() Notimplemented')
  0%|                                                                                                                                                                                                                                    | 0/100 [00:00<?, ?it/s]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  1%|██▏                                                                                                                                                                                                                       | 1/100 [00:47<1:18:54, 47.82s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  2%|████▎                                                                                                                                                                                                                     | 2/100 [01:30<1:13:06, 44.76s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  3%|██████▌                                                                                                                                                                                                                   | 3/100 [02:12<1:10:23, 43.54s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  4%|████████▋                                                                                                                                                                                                                 | 4/100 [02:55<1:09:09, 43.23s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  5%|██████████▉                                                                                                                                                                                                               | 5/100 [03:37<1:07:48, 42.83s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  6%|█████████████                                                                                                                                                                                                             | 6/100 [04:19<1:06:51, 42.68s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  7%|███████████████▎                                                                                                                                                                                                          | 7/100 [05:02<1:06:12, 42.72s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  8%|█████████████████▍                                                                                                                                                                                                        | 8/100 [05:44<1:05:09, 42.50s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  9%|███████████████████▌                                                                                                                                                                                                      | 9/100 [06:25<1:03:45, 42.04s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 10%|█████████████████████▋                                                                                                                                                                                                   | 10/100 [07:06<1:02:25, 41.61s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 11%|███████████████████████▊                                                                                                                                                                                                 | 11/100 [07:46<1:01:11, 41.25s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 12%|██████████████████████████                                                                                                                                                                                               | 12/100 [08:26<1:00:01, 40.93s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 13%|████████████████████████████▍                                                                                                                                                                                              | 13/100 [09:06<58:52, 40.60s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 14%|██████████████████████████████▋                                                                                                                                                                                            | 14/100 [09:46<57:45, 40.30s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 15%|████████████████████████████████▊                                                                                                                                                                                          | 15/100 [10:25<56:43, 40.04s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 16%|███████████████████████████████████                                                                                                                                                                                        | 16/100 [11:05<55:42, 39.79s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 17%|█████████████████████████████████████▏                                                                                                                                                                                     | 17/100 [11:44<54:46, 39.60s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 18%|███████████████████████████████████████▍                                                                                                                                                                                   | 18/100 [12:23<53:58, 39.49s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 19%|█████████████████████████████████████████▌                                                                                                                                                                                 | 19/100 [13:01<52:54, 39.19s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 20%|███████████████████████████████████████████▊                                                                                                                                                                               | 20/100 [13:40<52:00, 39.01s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 21%|█████████████████████████████████████████████▉                                                                                                                                                                             | 21/100 [14:18<50:53, 38.65s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 22%|████████████████████████████████████████████████▏                                                                                                                                                                          | 22/100 [14:56<50:01, 38.48s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 23%|██████████████████████████████████████████████████▎                                                                                                                                                                        | 23/100 [15:33<48:59, 38.17s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 24%|████████████████████████████████████████████████████▌                                                                                                                                                                      | 24/100 [16:11<48:03, 37.94s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 25%|██████████████████████████████████████████████████████▊                                                                                                                                                                    | 25/100 [16:49<47:21, 37.89s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 26%|████████████████████████████████████████████████████████▉                                                                                                                                                                  | 26/100 [17:26<46:44, 37.90s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 27%|███████████████████████████████████████████████████████████▏                                                                                                                                                               | 27/100 [18:04<45:54, 37.74s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 28%|█████████████████████████████████████████████████████████████▎                                                                                                                                                             | 28/100 [18:41<45:09, 37.63s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 29%|███████████████████████████████████████████████████████████████▌                                                                                                                                                           | 29/100 [19:18<44:11, 37.34s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 30%|█████████████████████████████████████████████████████████████████▋                                                                                                                                                         | 30/100 [19:55<43:30, 37.30s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 31%|███████████████████████████████████████████████████████████████████▉                                                                                                                                                       | 31/100 [20:32<42:48, 37.23s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 32%|██████████████████████████████████████████████████████████████████████                                                                                                                                                     | 32/100 [21:08<41:45, 36.84s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 33%|████████████████████████████████████████████████████████████████████████▎                                                                                                                                                  | 33/100 [21:44<40:42, 36.46s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 34%|██████████████████████████████████████████████████████████████████████████▍                                                                                                                                                | 34/100 [22:20<40:00, 36.37s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 35%|████████████████████████████████████████████████████████████████████████████▋                                                                                                                                              | 35/100 [22:56<39:14, 36.23s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 36%|██████████████████████████████████████████████████████████████████████████████▊                                                                                                                                            | 36/100 [23:31<38:27, 36.06s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 37%|█████████████████████████████████████████████████████████████████████████████████                                                                                                                                          | 37/100 [24:07<37:43, 35.94s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 38%|███████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                       | 38/100 [24:43<37:17, 36.09s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 39%|█████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                     | 39/100 [25:19<36:39, 36.06s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 40%|███████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                   | 40/100 [25:55<35:48, 35.82s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 41%|█████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                 | 41/100 [26:31<35:15, 35.86s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 42%|███████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                               | 42/100 [27:06<34:31, 35.72s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                            | 43/100 [27:41<33:40, 35.44s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                          | 44/100 [28:16<32:55, 35.28s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                        | 45/100 [28:51<32:20, 35.29s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 46%|████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                      | 46/100 [29:25<31:27, 34.95s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                    | 47/100 [30:01<31:06, 35.21s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                  | 48/100 [30:36<30:33, 35.27s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                               | 49/100 [31:11<29:52, 35.15s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                               | 49/100 [31:47<33:04, 38.92s/it]
  0%|                                                                                                                                                                                                                                     | 0/25 [00:00<?, ?it/s]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  4%|████████▊                                                                                                                                                                                                                    | 1/25 [00:00<00:04,  5.13it/s]  8%|█████████████████▋                                                                                                                                                                                                           | 2/25 [00:00<00:03,  5.91it/s] 12%|██████████████████████████▌                                                                                                                                                                                                  | 3/25 [00:00<00:03,  5.99it/s] 16%|███████████████████████████████████▎                                                                                                                                                                                         | 4/25 [00:00<00:03,  5.81it/s] 20%|████████████████████████████████████████████▏                                                                                                                                                                                | 5/25 [00:00<00:03,  5.56it/s] 24%|█████████████████████████████████████████████████████                                                                                                                                                                        | 6/25 [00:01<00:03,  5.30it/s] 28%|█████████████████████████████████████████████████████████████▉                                                                                                                                                               | 7/25 [00:01<00:03,  5.01it/s] 32%|██████████████████████████████████████████████████████████████████████▋                                                                                                                                                      | 8/25 [00:01<00:03,  4.67it/s] 36%|███████████████████████████████████████████████████████████████████████████████▌                                                                                                                                             | 9/25 [00:02<00:05,  3.04it/s] 40%|████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                    | 10/25 [00:02<00:05,  2.89it/s] 44%|████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                           | 11/25 [00:02<00:05,  2.76it/s] 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                  | 12/25 [00:03<00:04,  2.65it/s] 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                         | 13/25 [00:03<00:04,  2.55it/s] 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                | 14/25 [00:04<00:04,  2.46it/s] 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                        | 15/25 [00:04<00:04,  2.06it/s] 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                               | 16/25 [00:05<00:04,  2.08it/s] 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                      | 17/25 [00:05<00:03,  2.07it/s] 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                             | 18/25 [00:06<00:04,  1.71it/s] 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 19/25 [00:07<00:03,  1.67it/s] 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                            | 20/25 [00:07<00:03,  1.63it/s] 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                   | 21/25 [00:08<00:02,  1.44it/s] 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                          | 22/25 [00:09<00:02,  1.46it/s] 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 23/25 [00:10<00:01,  1.45it/s] 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏        | 24/25 [00:11<00:00,  1.32it/s]100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:11<00:00,  1.34it/s]100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:11<00:00,  2.12it/s]
