Loading pytorch-gpu/py3/2.7.0
  Loading requirement: gcc/11.4.1 cuda/12.6.3 nccl/2.25.1-1-cuda
    cudnn/9.5.1.17-cuda openmpi/4.1.6-cuda intel-mkl/2020.4 magma/2.9.0-cuda
    sox/14.4.2 hdf5/1.12.0-mpi-cuda libjpeg-turbo/2.1.3 ffmpeg/6.1.1
    openjdk/11.0.2
/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/selectionStrategy/random.py:30: UserWarning: get_params() Notimplemented
  warnings.warn('get_params() Notimplemented')
  0%|                                                                                                                                                                                                     | 0/100 [00:00<?, ?it/s]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  1%|█▊                                                                                                                                                                                        | 1/100 [03:40<6:03:04, 220.04s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  2%|███▋                                                                                                                                                                                      | 2/100 [07:19<5:59:17, 219.98s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  3%|█████▌                                                                                                                                                                                    | 3/100 [11:02<5:57:18, 221.02s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  4%|███████▍                                                                                                                                                                                  | 4/100 [14:43<5:53:37, 221.02s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  5%|█████████▎                                                                                                                                                                                | 5/100 [18:24<5:49:48, 220.93s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  6%|███████████▏                                                                                                                                                                              | 6/100 [22:05<5:46:23, 221.10s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  7%|█████████████                                                                                                                                                                             | 7/100 [25:46<5:42:48, 221.16s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  8%|██████████████▉                                                                                                                                                                           | 8/100 [29:29<5:39:49, 221.63s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  9%|████████████████▋                                                                                                                                                                         | 9/100 [33:10<5:36:04, 221.59s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 10%|██████████████████▌                                                                                                                                                                      | 10/100 [36:51<5:31:55, 221.29s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 11%|████████████████████▎                                                                                                                                                                    | 11/100 [40:33<5:28:43, 221.61s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 12%|██████████████████████▏                                                                                                                                                                  | 12/100 [44:15<5:24:58, 221.57s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 13%|████████████████████████                                                                                                                                                                 | 13/100 [47:57<5:21:28, 221.71s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 14%|█████████████████████████▉                                                                                                                                                               | 14/100 [51:38<5:17:26, 221.47s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 15%|███████████████████████████▊                                                                                                                                                             | 15/100 [55:19<5:13:30, 221.30s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 16%|█████████████████████████████▌                                                                                                                                                           | 16/100 [59:01<5:10:09, 221.54s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 17%|███████████████████████████████                                                                                                                                                        | 17/100 [1:02:55<5:11:51, 225.44s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 18%|████████████████████████████████▉                                                                                                                                                      | 18/100 [1:06:52<5:12:48, 228.89s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 19%|██████████████████████████████████▊                                                                                                                                                    | 19/100 [1:10:50<5:12:31, 231.50s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 20%|████████████████████████████████████▌                                                                                                                                                  | 20/100 [1:14:38<5:07:11, 230.40s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 21%|██████████████████████████████████████▍                                                                                                                                                | 21/100 [1:18:19<4:59:56, 227.80s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 22%|████████████████████████████████████████▎                                                                                                                                              | 22/100 [1:22:01<4:53:36, 225.85s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 23%|██████████████████████████████████████████                                                                                                                                             | 23/100 [1:25:42<4:48:17, 224.64s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 24%|███████████████████████████████████████████▉                                                                                                                                           | 24/100 [1:29:24<4:43:29, 223.81s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 25%|█████████████████████████████████████████████▊                                                                                                                                         | 25/100 [1:33:07<4:39:21, 223.49s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 26%|███████████████████████████████████████████████▌                                                                                                                                       | 26/100 [1:36:51<4:35:54, 223.72s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 27%|█████████████████████████████████████████████████▍                                                                                                                                     | 27/100 [1:40:47<4:36:38, 227.37s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 28%|███████████████████████████████████████████████████▏                                                                                                                                   | 28/100 [1:44:44<4:36:06, 230.09s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 29%|█████████████████████████████████████████████████████                                                                                                                                  | 29/100 [1:48:39<4:34:13, 231.73s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 30%|██████████████████████████████████████████████████████▉                                                                                                                                | 30/100 [1:52:35<4:31:54, 233.06s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 31%|████████████████████████████████████████████████████████▋                                                                                                                              | 31/100 [1:56:27<4:27:40, 232.76s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 32%|██████████████████████████████████████████████████████████▌                                                                                                                            | 32/100 [2:00:10<4:20:13, 229.62s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 33%|████████████████████████████████████████████████████████████▍                                                                                                                          | 33/100 [2:03:52<4:14:02, 227.50s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 34%|██████████████████████████████████████████████████████████████▏                                                                                                                        | 34/100 [2:07:36<4:08:57, 226.33s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 35%|████████████████████████████████████████████████████████████████                                                                                                                       | 35/100 [2:11:18<4:03:52, 225.12s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 36%|█████████████████████████████████████████████████████████████████▉                                                                                                                     | 36/100 [2:15:00<3:59:02, 224.11s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 37%|███████████████████████████████████████████████████████████████████▋                                                                                                                   | 37/100 [2:18:41<3:54:21, 223.19s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 38%|█████████████████████████████████████████████████████████████████████▌                                                                                                                 | 38/100 [2:22:21<3:49:38, 222.24s/it]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
 38%|█████████████████████████████████████████████████████████████████████▌                                                                                                                 | 38/100 [2:26:01<3:58:14, 230.56s/it]
  0%|                                                                                                                                                                                                      | 0/16 [00:00<?, ?it/s]/lustre/fsn1/projects/rech/enh/unv34ei/MICAT/micat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /lustre/fshomisc/sup/hpe/src/pub/miniforge/24.11.3/pytorch-gpu-2.7.0+py3.12.10+cuda-12.6/pytorch-2.7.0/build/aten/src/ATen/core/TensorBody.h:489.)
  if getattr(p, "grad", None) is not None:
  6%|███████████▉                                                                                                                                                                                  | 1/16 [00:00<00:06,  2.34it/s] 12%|███████████████████████▊                                                                                                                                                                      | 2/16 [00:01<00:10,  1.35it/s] 19%|███████████████████████████████████▋                                                                                                                                                          | 3/16 [00:02<00:11,  1.12it/s] 25%|███████████████████████████████████████████████▌                                                                                                                                              | 4/16 [00:04<00:14,  1.17s/it] 31%|███████████████████████████████████████████████████████████▍                                                                                                                                  | 5/16 [00:06<00:16,  1.49s/it] 38%|███████████████████████████████████████████████████████████████████████▎                                                                                                                      | 6/16 [00:08<00:17,  1.79s/it] 44%|███████████████████████████████████████████████████████████████████████████████████▏                                                                                                          | 7/16 [00:11<00:18,  2.08s/it] 50%|███████████████████████████████████████████████████████████████████████████████████████████████                                                                                               | 8/16 [00:14<00:19,  2.45s/it] 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                   | 9/16 [00:17<00:19,  2.72s/it] 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                      | 10/16 [00:21<00:18,  3.10s/it] 69%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                           | 11/16 [00:25<00:17,  3.47s/it] 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                               | 12/16 [00:30<00:15,  3.82s/it] 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                   | 13/16 [00:35<00:12,  4.15s/it] 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 14/16 [00:41<00:09,  4.58s/it] 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏           | 15/16 [00:46<00:04,  4.92s/it]100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:52<00:00,  5.31s/it]100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:52<00:00,  3.31s/it]
