{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78a21ce669eb601d",
   "metadata": {},
   "source": [
    "# Liriscat paper experiments\n",
    "### 1. Init\n",
    "#### 1.1. Import libraries (necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b0d5d27c5b782ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:00:43.125550Z",
     "start_time": "2025-03-28T16:00:41.971774Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
    "\n",
    "import liriscat\n",
    "liriscat.utils.set_seed(0)\n",
    "\n",
    "import logging\n",
    "import gc\n",
    "import json\n",
    "import torch\n",
    "liriscat.utils.set_seed(0)\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "import IMPACT\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edbbd0515734832",
   "metadata": {},
   "source": [
    "#### 1.2. Set up the loggers (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b358c4709ccb3845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T16:01:06.271337Z",
     "start_time": "2025-03-27T16:01:06.259238Z"
    }
   },
   "outputs": [],
   "source": [
    "liriscat.utils.setuplogger(verbose = True, log_name=\"liriscat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44435df786608165",
   "metadata": {},
   "source": [
    "### 2. CDM prediction\n",
    "#### 2.1. Training and testing, sequential version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d2be5c98d6482",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T16:01:07.182919Z",
     "start_time": "2025-03-27T16:01:06.322894Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f0f4ece676cf862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T16:01:07.264870Z",
     "start_time": "2025-03-27T16:01:07.250580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n",
      "[INFO 44:34] math2\n"
     ]
    }
   ],
   "source": [
    "config = liriscat.utils.generate_eval_config(load_params=True, esc = 'error', valid_metric= 'mi_acc', pred_metrics = [\"mi_acc\"], profile_metrics = ['doa'], save_params=False, n_query=4, num_epochs=1, batch_size=512)\n",
    "liriscat.utils.set_seed(config[\"seed\"])\n",
    "\n",
    "config[\"dataset_name\"] = \"math2\"\n",
    "logging.info(config[\"dataset_name\"])\n",
    "config['learning_rate'] = 0.02026\n",
    "config['lambda'] = 1.2e-5\n",
    "config['d_in'] = 4\n",
    "config['num_responses'] = 12\n",
    "#pred_metrics,df_interp = test(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25de2dcd379383e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 44:34] #### math2 ####\n",
      "[INFO 44:34] #### config : {'seed': 0, 'dataset_name': 'math2', 'load_params': True, 'save_params': False, 'embs_path': '../embs/', 'params_path': '../ckpt/', 'early_stopping': True, 'esc': 'error', 'verbose_early_stopping': False, 'disable_tqdm': False, 'valid_metric': 'mi_acc', 'learning_rate': 0.02026, 'batch_size': 512, 'valid_batch_size': 10000, 'num_epochs': 1, 'eval_freq': 1, 'patience': 30, 'device': device(type='cuda'), 'lambda': 1.2e-05, 'tensorboard': False, 'flush_freq': True, 'pred_metrics': ['mi_acc'], 'profile_metrics': ['doa'], 'num_responses': 12, 'low_mem': False, 'n_query': 4, 'CDM': 'impact', 'i_fold': 0, 'num_inner_users_epochs': 10, 'num_inner_epochs': 10, 'inner_lr': 0.0001, 'inner_user_lr': 0.0001, 'new_users_framework': True, 'meta_trainer': 'Adam', 'd_in': 4} ####\n"
     ]
    }
   ],
   "source": [
    "logging.info(f'#### {config[\"dataset_name\"]} ####')\n",
    "logging.info(f'#### config : {config} ####')\n",
    "config['embs_path']='../embs/'+str(config[\"dataset_name\"])\n",
    "config['params_path']='../ckpt/'+str(config[\"dataset_name\"])\n",
    "\n",
    "pred_metrics = {m:[] for m in config['pred_metrics']}\n",
    "profile_metrics = {m:[] for m in config['profile_metrics']}\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Dataset downloading for doa and rm\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in divide\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "## Concept map format : {question_id : [category_id1, category_id2, ...]}\n",
    "concept_map = json.load(open(f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_concept_map.json', 'r'))\n",
    "concept_map = {int(k): [int(x) for x in v] for k, v in concept_map.items()}\n",
    "\n",
    "## Metadata map format : {\"num_user_id\": ..., \"num_item_id\": ..., \"num_dimension_id\": ...}\n",
    "metadata = json.load(open(f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_metadata.json', 'r'))\n",
    "\n",
    "\n",
    "## Tensor containing the nb of modalities per question\n",
    "nb_modalities = torch.load(f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_nb_modalities.pkl',weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0eddc4ac5ebfbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 44:45] Random_cont_model\n",
      "compiling CDM model\n",
      "compiling selection model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Embedding.forward() missing 1 required positional argument: 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m#S.train(train_data, valid_data)\u001b[39;00m\n\u001b[32m     25\u001b[39m S.reset_rng()\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/liriscat/liriscat/selectionStrategy/abstract_selection_strategy.py:287\u001b[39m, in \u001b[36mAbstractSelectionStrategy.evaluation_state.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.eval() \u001b[38;5;66;03m# todo : putting in eval mode again\u001b[39;00m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad(), torch.amp.autocast(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m         result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    289\u001b[39m     \u001b[38;5;66;03m# Restore the previous state after method execution\u001b[39;00m\n\u001b[32m    290\u001b[39m     \u001b[38;5;28mself\u001b[39m.CDM.model.train()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/liriscat/liriscat/selectionStrategy/abstract_selection_strategy.py:379\u001b[39m, in \u001b[36mAbstractSelectionStrategy.evaluate_test\u001b[39m\u001b[34m(self, test_dataset)\u001b[39m\n\u001b[32m    376\u001b[39m actions = \u001b[38;5;28mself\u001b[39m.select_action(options)\n\u001b[32m    377\u001b[39m test_query_env.update(actions, t)\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minner_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_query_env\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeed_IMPACT_sub\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmeta_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad() :\n\u001b[32m    382\u001b[39m     preds = \u001b[38;5;28mself\u001b[39m.CDM.model(meta_data[\u001b[33m'\u001b[39m\u001b[33musers_id\u001b[39m\u001b[33m'\u001b[39m], meta_data[\u001b[33m'\u001b[39m\u001b[33mquestions_id\u001b[39m\u001b[33m'\u001b[39m], meta_data[\u001b[33m'\u001b[39m\u001b[33mcategories_id\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/liriscat/liriscat/selectionStrategy/abstract_selection_strategy.py:186\u001b[39m, in \u001b[36mAbstractSelectionStrategy.Adam_inner_loop\u001b[39m\u001b[34m(self, query_data, meta_data)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mAdam_inner_loop\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_data, meta_data):\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     user_params_optimizer = torch.optim.Adam(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mCDM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43musers_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.parameters(),\n\u001b[32m    187\u001b[39m                                                 lr=\u001b[38;5;28mself\u001b[39m.CDM.config[\n\u001b[32m    188\u001b[39m                                                     \u001b[33m'\u001b[39m\u001b[33minner_user_lr\u001b[39m\u001b[33m'\u001b[39m])  \u001b[38;5;66;03m# todo : Decide How to use a scheduler\u001b[39;00m\n\u001b[32m    189\u001b[39m     user_params_scaler = torch.amp.GradScaler(\u001b[38;5;28mself\u001b[39m.CDM.config[\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtake_step\u001b[39m(user_ids, question_ids, labels, category_ids):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/liriscat/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/liriscat/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mTypeError\u001b[39m: Embedding.forward() missing 1 required positional argument: 'input'"
     ]
    }
   ],
   "source": [
    "config['inner_user_lr'] = 0.01\n",
    "config['num_inner_users_epochs'] = 8\n",
    "for i_fold in range(1) : \n",
    "    ## Dataframe columns : (user_id, question_id, response, category_id)\n",
    "    train_df = pd.read_csv(\n",
    "        f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_train_{i_fold}.csv',\n",
    "        encoding='utf-8', dtype={'student_id': int, 'item_id': int, \"correct\": float,\n",
    "                                                                 \"dimension_id\": int})\n",
    "    valid_df = pd.read_csv(\n",
    "        f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_valid_{i_fold}.csv',\n",
    "        encoding='utf-8', dtype={'student_id': int, 'item_id': int, \"correct\": float,\n",
    "                                                                 \"dimension_id\": int})\n",
    "    test_df = pd.read_csv(\n",
    "        f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_test_{i_fold}.csv',\n",
    "        encoding='utf-8', dtype={'student_id': int, 'item_id': int, \"correct\": float,\n",
    "                                                                 \"dimension_id\": int})\n",
    "\n",
    "    train_data = liriscat.dataset.CATDataset(train_df, concept_map, metadata, config,nb_modalities)\n",
    "    valid_data = liriscat.dataset.EvalDataset(valid_df, concept_map, metadata, config,nb_modalities)\n",
    "    test_data = liriscat.dataset.EvalDataset(test_df, concept_map, metadata, config,nb_modalities)\n",
    "\n",
    "    S = liriscat.selectionStrategy.Random(metadata,**config)\n",
    "    S.init_models(train_data, valid_data)\n",
    "    #S.train(train_data, valid_data)\n",
    "    S.reset_rng()\n",
    "    print(S.evaluate_test(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0d84b3073e46eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 22:31] Random_cont_model\n",
      "compiling CDM model\n",
      "compiling selection model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CATIMPACT' object has no attribute 'users_emb'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#S.train(train_data, valid_data)\u001b[39;00m\n\u001b[32m     10\u001b[39m S.reset_rng()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/liriscat/liriscat/selectionStrategy/abstract_selection_strategy.py:287\u001b[39m, in \u001b[36mAbstractSelectionStrategy.evaluation_state.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.eval() \u001b[38;5;66;03m# todo : putting in eval mode again\u001b[39;00m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad(), torch.amp.autocast(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m         result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    289\u001b[39m     \u001b[38;5;66;03m# Restore the previous state after method execution\u001b[39;00m\n\u001b[32m    290\u001b[39m     \u001b[38;5;28mself\u001b[39m.CDM.model.train()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/liriscat/liriscat/selectionStrategy/abstract_selection_strategy.py:379\u001b[39m, in \u001b[36mAbstractSelectionStrategy.evaluate_test\u001b[39m\u001b[34m(self, test_dataset)\u001b[39m\n\u001b[32m    376\u001b[39m actions = \u001b[38;5;28mself\u001b[39m.select_action(options)\n\u001b[32m    377\u001b[39m test_query_env.update(actions, t)\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minner_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_query_env\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeed_IMPACT_sub\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmeta_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad() :\n\u001b[32m    382\u001b[39m     preds = \u001b[38;5;28mself\u001b[39m.CDM.model(meta_data[\u001b[33m'\u001b[39m\u001b[33musers_id\u001b[39m\u001b[33m'\u001b[39m], meta_data[\u001b[33m'\u001b[39m\u001b[33mquestions_id\u001b[39m\u001b[33m'\u001b[39m], meta_data[\u001b[33m'\u001b[39m\u001b[33mcategories_id\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/liriscat/liriscat/selectionStrategy/abstract_selection_strategy.py:202\u001b[39m, in \u001b[36mAbstractSelectionStrategy.Adam_inner_loop\u001b[39m\u001b[34m(self, query_data, meta_data)\u001b[39m\n\u001b[32m    199\u001b[39m     user_params_scaler.step(user_params_optimizer)\n\u001b[32m    200\u001b[39m     user_params_scaler.update()\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mabstract_inner_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtake_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/liriscat/liriscat/selectionStrategy/abstract_selection_strategy.py:230\u001b[39m, in \u001b[36mAbstractSelectionStrategy.abstract_inner_loop\u001b[39m\u001b[34m(self, query_data, meta_data, optimizer)\u001b[39m\n\u001b[32m    228\u001b[39m     sum_acc_0 += utils.micro_ave_accuracy(labels, preds)\n\u001b[32m    229\u001b[39m     meta_preds = \u001b[38;5;28mself\u001b[39m.CDM.model(users_id=meta_data[\u001b[33m'\u001b[39m\u001b[33musers_id\u001b[39m\u001b[33m'\u001b[39m], items_id=meta_data[\u001b[33m'\u001b[39m\u001b[33mquestions_id\u001b[39m\u001b[33m'\u001b[39m], concepts_id=meta_data[\u001b[33m'\u001b[39m\u001b[33mcategories_id\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     loss2 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mCDM\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_compute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43musers_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43musers_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitems_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mitems_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m     sum_loss_1 += loss2.item()\n\u001b[32m    233\u001b[39m \u001b[38;5;28mself\u001b[39m.CDM.model.train()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/liriscat/liriscat/CDM/IMPACT.py:99\u001b[39m, in \u001b[36mCATIMPACT._compute_loss\u001b[39m\u001b[34m(self, users_id, items_id, concepts_id, labels)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compute_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, users_id, items_id, concepts_id=\u001b[38;5;28;01mNone\u001b[39;00m, labels=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     97\u001b[39m     lambda_param = \u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mlambda\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     u_emb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_users_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43musers_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m     im_emb_prime = \u001b[38;5;28mself\u001b[39m.model.get_modalities_emb(items_id)\n\u001b[32m    103\u001b[39m     L1 = \u001b[38;5;28mself\u001b[39m.custom_l1(u_emb=u_emb,\n\u001b[32m    104\u001b[39m         im_emb_prime=im_emb_prime,\n\u001b[32m    105\u001b[39m         modalities_idx=\u001b[38;5;28mself\u001b[39m.model.ir_idx[users_id, items_id],\n\u001b[32m    106\u001b[39m         nb_mod_max_plus_sent=\u001b[38;5;28mself\u001b[39m.model.nb_mod_max_plus_sent,\n\u001b[32m    107\u001b[39m         diff_mask=\u001b[38;5;28mself\u001b[39m.model.diff_mask[items_id])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:3\u001b[39m, in \u001b[36mget_users_emb\u001b[39m\u001b[34m(self, users_id)\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: 'CATIMPACT' object has no attribute 'users_emb'"
     ]
    }
   ],
   "source": [
    "# Important for reproducibility\n",
    "train_data.reset_rng()\n",
    "valid_data.reset_rng()\n",
    "test_data.reset_rng()\n",
    "\n",
    "S = liriscat.selectionStrategy.Random(metadata,**config)\n",
    "S.init_models(train_data, valid_data)\n",
    "#S.train(train_data, valid_data)\n",
    "\n",
    "S.reset_rng()\n",
    "print(S.evaluate_test(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303135b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (liriscat no frozen)",
   "language": "python",
   "name": "liriscat-nofrozen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
