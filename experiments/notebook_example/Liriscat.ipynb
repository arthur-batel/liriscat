{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# IMPACT paper experiments\n",
    "### 1. Init\n",
    "#### 1.1. Import libraries (necessary)"
   ],
   "id": "78a21ce669eb601d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T16:21:09.471539Z",
     "start_time": "2025-03-05T16:21:08.093750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "from liriscat import utils\n",
    "utils.set_seed(0)\n",
    "from liriscat import dataset\n",
    "from liriscat import model\n",
    "\n",
    "import logging\n",
    "import gc\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from importlib import reload"
   ],
   "id": "5b0d5d27c5b782ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Skipping CUDA seed setting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthurb/Programmation/liriscat/y/envs/liriscat-env/lib/python3.12/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.2. Set up the loggers (recommended)",
   "id": "7edbbd0515734832"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T15:22:08.071670Z",
     "start_time": "2025-03-05T15:22:08.058923Z"
    }
   },
   "cell_type": "code",
   "source": "utils.setuplogger(verbose = True, log_name=\"liriscat\")",
   "id": "b358c4709ccb3845",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. CDM prediction\n",
    "#### 2.1. Training and testing, sequential version"
   ],
   "id": "44435df786608165"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T15:25:18.038839Z",
     "start_time": "2025-03-05T15:25:17.965458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "reload(utils)\n",
    "reload(model)\n",
    "reload(dataset)\n"
   ],
   "id": "83d2be5c98d6482",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'liriscat.dataset' from '/home/arthurb/Programmation/liriscat/liriscat/dataset/__init__.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T15:25:52.038254Z",
     "start_time": "2025-03-05T15:25:52.024513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = utils.generate_eval_config(esc = 'error', valid_metric= 'rmse', pred_metrics = ['rmse', 'mae'], profile_metrics = ['doa', 'pc-er', 'rm'], save_params=False)\n",
    "utils.set_seed(config[\"seed\"])\n",
    "\n",
    "config[\"dataset_name\"] = \"assist0910\"\n",
    "logging.info(config[\"dataset_name\"])\n",
    "config['learning_rate'] = 0.02026\n",
    "config['lambda'] = 1.2e-5\n",
    "config['d_in'] = 4\n",
    "config['num_responses'] = 12\n",
    "#pred_metrics,df_interp = test(config)"
   ],
   "id": "7f0f4ece676cf862",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n",
      "[INFO 25:52] assist0910\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T15:27:22.251151Z",
     "start_time": "2025-03-05T15:27:22.173445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logging.info(f'#### {config[\"dataset_name\"]} ####')\n",
    "logging.info(f'#### config : {config} ####')\n",
    "config['embs_path']='../embs/'+str(config[\"dataset_name\"])\n",
    "config['params_path']='../ckpt/'+str(config[\"dataset_name\"])\n",
    "\n",
    "pred_metrics = {m:[] for m in config['pred_metrics']}\n",
    "profile_metrics = {m:[] for m in config['profile_metrics']}\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Dataset downloading for doa and rm\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in divide\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "## Concept map format : {question_id : [category_id1, category_id2, ...]}\n",
    "concept_map = json.load(open(f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_concept_map.json', 'r'))\n",
    "concept_map = {int(k): [int(x) for x in v] for k, v in concept_map.items()}\n",
    "\n",
    "## Metadata map format : {\"num_user_id\": ..., \"num_item_id\": ..., \"num_dimension_id\": ...}\n",
    "metadata = json.load(open(f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_metadata.json', 'r'))"
   ],
   "id": "87478e50750bcb2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 27:22] #### assist0910 ####\n",
      "[INFO 27:22] #### config : {'seed': 0, 'dataset_name': 'assist0910', 'load_params': False, 'save_params': False, 'embs_path': '../embs/assist0910', 'params_path': '../ckpt/assist0910', 'early_stopping': True, 'esc': 'error', 'verbose_early_stopping': False, 'disable_tqdm': False, 'valid_metric': 'rmse', 'learning_rate': 0.02026, 'batch_size': 2048, 'num_epochs': 200, 'eval_freq': 1, 'patience': 30, 'device': device(type='cuda'), 'lambda': 1.2e-05, 'tensorboard': False, 'flush_freq': True, 'pred_metrics': ['rmse', 'mae'], 'profile_metrics': ['doa', 'pc-er', 'rm'], 'num_responses': 12, 'low_mem': False, 'd_in': 4} ####\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "i_fold = 0\n",
    "## Dataframe columns : (user_id, question_id, response, category_id)\n",
    "train_df = pd.read_csv(\n",
    "    f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_train_{i_fold}.csv',\n",
    "    encoding='utf-8', dtype={'student_id': int, 'item_id': int, \"correct\": float,\n",
    "                                                             \"dimension_id\": int})\n",
    "valid_df = pd.read_csv(\n",
    "    f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_valid_{i_fold}.csv',\n",
    "    encoding='utf-8', dtype={'student_id': int, 'item_id': int, \"correct\": float,\n",
    "                                                             \"dimension_id\": int})\n",
    "test_df = pd.read_csv(\n",
    "    f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_test_{i_fold}.csv',\n",
    "    encoding='utf-8', dtype={'student_id': int, 'item_id': int, \"correct\": float,\n",
    "                                                             \"dimension_id\": int})"
   ],
   "id": "f708e72f1ffe442f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T16:20:45.541554Z",
     "start_time": "2025-03-05T16:20:45.506028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reload(dataset)\n",
    "train_data = dataset.Dataset(train_df, concept_map, metadata, config)\n",
    "# valid_data = dataset.LoaderDataset(valid_quadruplets, concept_map, metadata)\n",
    "# test_data = dataset.LoaderDataset(test_quadruplets, concept_map, metadata)"
   ],
   "id": "486ca1c99057160d",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[35], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m reload(dataset)\n\u001B[0;32m----> 2\u001B[0m train_data \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconcept_map\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# valid_data = dataset.LoaderDataset(valid_quadruplets, concept_map, metadata)\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# test_data = dataset.LoaderDataset(test_quadruplets, concept_map, metadata)\u001B[39;00m\n",
      "File \u001B[0;32m~/Programmation/liriscat/liriscat/dataset/dataset.py:25\u001B[0m, in \u001B[0;36mDataset.__init__\u001B[0;34m(self, df, concept_map, metadata, config)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_config \u001B[38;5;241m=\u001B[39m config\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_np_array \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mto_numpy()\n\u001B[0;32m---> 25\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_torch_array \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_np_array\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdevice\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_log_tensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate_log_tensor()  \u001B[38;5;66;03m# precompute right away\u001B[39;00m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_users_id \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muser_id\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39munique() \u001B[38;5;66;03m# Ids of the users in this dataset instance (after splitting)\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T15:35:15.806451Z",
     "start_time": "2025-03-05T15:35:15.738722Z"
    }
   },
   "cell_type": "code",
   "source": "train_data.n_logs",
   "id": "385155a00cdfe812",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123494"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_by_u_q_optimized(u, q, random_state=None):\n",
    "    \"\"\"\n",
    "    Splits data tuples into two groups (e.g., query and meta) without separating tuples\n",
    "    that share the same (u, q) pair.\n",
    "\n",
    "    Optimized version: sorts the data by u so that each user's indices are contiguous,\n",
    "    then processes each block to assign a random group label per unique q.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    u : array-like\n",
    "        Array of user values.\n",
    "    q : array-like\n",
    "        Array of question values.\n",
    "    random_state : int or None, optional\n",
    "        Seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    groups : np.ndarray\n",
    "        Array of group labels (0 or 1) for each data tuple.\n",
    "    \"\"\"\n",
    "    # Convert to numpy arrays\n",
    "    u = np.asarray(u)\n",
    "    q = np.asarray(q)\n",
    "    groups = np.empty(u.shape[0], dtype=np.int8)\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    # Sort indices by u so that rows for the same user are contiguous.\n",
    "    sorted_u_idx = np.argsort(u)\n",
    "    u_sorted = u[sorted_u_idx]\n",
    "\n",
    "    # Find the boundaries for each unique user.\n",
    "    unique_users, start_idx = np.unique(u_sorted, return_index=True)\n",
    "    end_idx = np.append(start_idx[1:], len(u_sorted))\n",
    "\n",
    "    # Process each contiguous block corresponding to a single user.\n",
    "    for s, e in zip(start_idx, end_idx):\n",
    "        block_idx = sorted_u_idx[s:e]  # indices for one user\n",
    "        q_block = q[block_idx]\n",
    "        # For this user's block, get unique q values and an inverse index\n",
    "        unique_q, inv = np.unique(q_block, return_inverse=True)\n",
    "        # Randomly assign a group label (0 or 1) for each unique q in this block\n",
    "        group_assignments = rng.choice([0, 1], size=len(unique_q), p=[0.8,0.2])\n",
    "        # Map the group labels back to the original indices in the block\n",
    "        groups[block_idx] = group_assignments[inv]\n",
    "\n",
    "    return groups\n",
    "\n",
    "# Example usage:\n",
    "# Let's assume train[0] is a structured array/dict-like with keys 'user_id' and 'item_id'.\n",
    "# For demonstration, we simulate some sample data:\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "for i in range(1):\n",
    "    group_labels = split_by_u_q_optimized(train[0]['user_id'], train[0]['item_id'], random_state=42)\n",
    "\n",
    "    # Now, all tuples with the same (user_id, item_id) pair have the same group label.\n",
    "    query_mask = (group_labels == 0)\n",
    "    meta_mask  = (group_labels == 1)\n",
    "\n",
    "    query_users = train[0]['user_id'][query_mask].to_numpy()\n",
    "    query_questions = train[0]['item_id'][query_mask].to_numpy()\n",
    "    meta_users = train[0]['user_id'][meta_mask].to_numpy()\n",
    "    meta_questions = train[0]['item_id'][meta_mask].to_numpy()\n",
    "    #print(s2)\n",
    "print(\"Total time:\", time.time() - start)\n"
   ],
   "id": "initial_id"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
