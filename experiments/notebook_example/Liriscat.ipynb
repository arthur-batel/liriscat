{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# IMPACT paper experiments\n",
    "### 1. Init\n",
    "#### 1.1. Import libraries (necessary)"
   ],
   "id": "78a21ce669eb601d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "from liriscat import utils\n",
    "utils.set_seed(0)\n",
    "from liriscat import dataset\n",
    "from liriscat import selectionStrategy\n",
    "from liriscat import CDM\n",
    "\n",
    "import logging\n",
    "import gc\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "import IMPACT"
   ],
   "id": "5b0d5d27c5b782ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.2. Set up the loggers (recommended)",
   "id": "7edbbd0515734832"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "utils.setuplogger(verbose = True, log_name=\"liriscat\")",
   "id": "b358c4709ccb3845",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. CDM prediction\n",
    "#### 2.1. Training and testing, sequential version"
   ],
   "id": "44435df786608165"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "reload(utils)\n",
    "reload(selectionStrategy)\n",
    "reload(CDM)\n",
    "reload(dataset)"
   ],
   "id": "83d2be5c98d6482",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "config = utils.generate_eval_config(esc = 'error', valid_metric= 'mi_acc', pred_metrics = [\"mi_acc\"], profile_metrics = ['doa'], save_params=False, n_query=4, num_epochs=4, batch_size=512)\n",
    "utils.set_seed(config[\"seed\"])\n",
    "\n",
    "config[\"dataset_name\"] = \"math2\"\n",
    "logging.info(config[\"dataset_name\"])\n",
    "config['learning_rate'] = 0.02026\n",
    "config['lambda'] = 1.2e-5\n",
    "config['d_in'] = 4\n",
    "config['num_responses'] = 12\n",
    "#pred_metrics,df_interp = test(config)"
   ],
   "id": "7f0f4ece676cf862",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "logging.info(f'#### {config[\"dataset_name\"]} ####')\n",
    "logging.info(f'#### config : {config} ####')\n",
    "config['embs_path']='../embs/'+str(config[\"dataset_name\"])\n",
    "config['params_path']='../ckpt/'+str(config[\"dataset_name\"])\n",
    "\n",
    "pred_metrics = {m:[] for m in config['pred_metrics']}\n",
    "profile_metrics = {m:[] for m in config['profile_metrics']}\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Dataset downloading for doa and rm\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in divide\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "## Concept map format : {question_id : [category_id1, category_id2, ...]}\n",
    "concept_map = json.load(open(f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_concept_map.json', 'r'))\n",
    "concept_map = {int(k): [int(x) for x in v] for k, v in concept_map.items()}\n",
    "\n",
    "## Metadata map format : {\"num_user_id\": ..., \"num_item_id\": ..., \"num_dimension_id\": ...}\n",
    "metadata = json.load(open(f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_metadata.json', 'r'))"
   ],
   "id": "87478e50750bcb2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "i_fold = 0\n",
    "## Dataframe columns : (user_id, question_id, response, category_id)\n",
    "train_df = pd.read_csv(\n",
    "    f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_train_{i_fold}.csv',\n",
    "    encoding='utf-8', dtype={'student_id': int, 'item_id': int, \"correct\": float,\n",
    "                                                             \"dimension_id\": int})\n",
    "valid_df = pd.read_csv(\n",
    "    f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_valid_{i_fold}.csv',\n",
    "    encoding='utf-8', dtype={'student_id': int, 'item_id': int, \"correct\": float,\n",
    "                                                             \"dimension_id\": int})\n",
    "test_df = pd.read_csv(\n",
    "    f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_test_{i_fold}.csv',\n",
    "    encoding='utf-8', dtype={'student_id': int, 'item_id': int, \"correct\": float,\n",
    "                                                             \"dimension_id\": int})"
   ],
   "id": "f708e72f1ffe442f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "reload(dataset)\n",
    "train_data = dataset.CATDataset(train_df, concept_map, metadata, config)\n",
    "valid_data = dataset.EvalDataset(valid_df, concept_map, metadata, config)\n",
    "test_data = dataset.EvalDataset(test_df, concept_map, metadata, config)"
   ],
   "id": "486ca1c99057160d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "reload(utils)\n",
    "reload(selectionStrategy)\n",
    "reload(dataset)\n",
    "reload(CDM)\n",
    "\n",
    "S = selectionStrategy.Random(**config)\n"
   ],
   "id": "ff57deb0c18c1ce0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "S.train(train_data, valid_data)"
   ],
   "id": "357d67780a6318ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T21:56:37.809339Z",
     "start_time": "2025-03-26T21:56:33.793712Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e82a1f61fa249718",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_loader = torch.utils.data.DataLoader(impact_valid_data, batch_size=1, shuffle=False)",
   "id": "9f13cd42033992b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "U_resp_sum = torch.zeros(size=(S.CDM.model.user_n, S.CDM.model.concept_n)).to(S.device, non_blocking=True)\n",
    "U_resp_nb = torch.zeros(size=(S.CDM.model.user_n, S.CDM.model.concept_n)).to(S.device, non_blocking=True)\n",
    "\n",
    "S.CDM.model.eval()\n",
    "with torch.no_grad(), torch.amp.autocast('cuda'):\n",
    "    data_loader = torch.utils.data.DataLoader(impact_valid_data, batch_size=1, shuffle=False)\n",
    "    for data_batch in data_loader:\n",
    "        user_ids = data_batch[:, 0].long()\n",
    "        item_ids = data_batch[:, 1].long()\n",
    "        labels = data_batch[:, 2]\n",
    "        dim_ids = data_batch[:, 3].long()\n",
    "\n",
    "        U_resp_sum[user_ids, dim_ids] += labels\n",
    "        U_resp_nb[user_ids, dim_ids] += torch.ones_like(labels)"
   ],
   "id": "c0cfa71c9968eee9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3a992db6a74b95b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "S.CDM.init_model(impact_train_data, impact_valid_data)\n",
    "S.CDM.model.to(S.device, non_blocking=True)\n",
    "S.CDM.train(train_data, valid_data)\n"
   ],
   "id": "11513b1a66b033af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_data.split_query_meta(2)\n",
    "S.evaluate_test(test_data)"
   ],
   "id": "962714f73f2fcc49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "saved_mi_acc = [0.643, 0.6379999999999999, 0.645, 0.661, 0.6679999999999999, 0.675, 0.6890000000000001, 0.7010000000000001]\n",
    "\n",
    "saved_doa = [0.506,0.564,0.576,0.588,0.604,0.612,0.685,0.702]"
   ],
   "id": "8344c082c74fe1c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# First plot\n",
    "color1 = 'b'\n",
    "ln1 = ax1.plot(saved_mi_acc, color1, label='mi_acc')\n",
    "ax1.set_xlabel('Number of submitted questions')\n",
    "ax1.set_ylabel('Micro averaged accuracy', color=color1)\n",
    "ax1.tick_params(axis='y', labelcolor=color1)\n",
    "\n",
    "# Twin axis for second plot\n",
    "ax2 = ax1.twinx()\n",
    "color2 = 'r'\n",
    "ln2 = ax2.plot(saved_doa, color2, label='doa')\n",
    "ax2.set_ylabel('DOA', color=color2)\n",
    "ax2.tick_params(axis='y', labelcolor=color2)\n",
    "\n",
    "# Combine legends from both axes\n",
    "lns = ln1 + ln2\n",
    "labels = [l.get_label() for l in lns]\n",
    "ax1.legend(lns, labels, loc='best')\n",
    "\n",
    "plt.title('ACC et DOA of IMPACT on the Meta test set\\nover the number of Randomly submitted questions')\n",
    "plt.show()\n"
   ],
   "id": "425d458688d02aa9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ec79e13136a8fb38",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
