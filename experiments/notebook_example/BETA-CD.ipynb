{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78a21ce669eb601d",
   "metadata": {},
   "source": [
    "# Liriscat paper experiments\n",
    "### 1. Init\n",
    "#### 1.1. Import libraries (necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b0d5d27c5b782ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:00:43.125550Z",
     "start_time": "2025-03-28T16:00:41.971774Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
    "\n",
    "import liriscat\n",
    "liriscat.utils.set_seed(0)\n",
    "\n",
    "import logging\n",
    "import gc\n",
    "import json\n",
    "import torch\n",
    "liriscat.utils.set_seed(0)\n",
    "import pandas as pd\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ab0bc4902808a9",
   "metadata": {},
   "source": [
    "#### 1.2. Set up the loggers (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b358c4709ccb3845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T16:01:06.271337Z",
     "start_time": "2025-03-27T16:01:06.259238Z"
    }
   },
   "outputs": [],
   "source": [
    "liriscat.utils.setuplogger(verbose = True, log_name=\"liriscat\", debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e97a539f6607db0",
   "metadata": {},
   "source": [
    "### 2. CDM prediction\n",
    "#### 2.1. Training and testing, sequential version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d2be5c98d6482",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T16:01:07.182919Z",
     "start_time": "2025-03-27T16:01:06.322894Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a54dc4f99eadbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n",
      "[INFO 36:20] math2\n"
     ]
    }
   ],
   "source": [
    "config = liriscat.utils.generate_eval_config(load_params=True, esc = 'error', valid_metric= 'mi_acc', pred_metrics = [\"mi_acc\"], profile_metrics = ['meta_doa'], save_params=False, n_query=6, num_epochs=100, batch_size=512)\n",
    "liriscat.utils.set_seed(config[\"seed\"])\n",
    "\n",
    "config[\"dataset_name\"] = \"math2\"\n",
    "logging.info(config[\"dataset_name\"])\n",
    "config['learning_rate'] = 0.0001\n",
    "config['inner_user_lr'] = 0.016848380924625605\n",
    "config['lambda'] = 9.972254466547545e-06\n",
    "\n",
    "config['meta_lr'] = 0.05\n",
    "config['kl_weight'] = 1e-3\n",
    "config['patience'] = 20#5\n",
    "config['num_inner_users_epochs'] = 3\n",
    "config['d_in'] = 4\n",
    "config['num_responses'] = 12\n",
    "\n",
    "#pred_metrics,df_interp = test(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73dcbf76e1d61f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 36:20] #### math2 ####\n",
      "[INFO 36:20] #### config : {'seed': 0, 'dataset_name': 'math2', 'load_params': True, 'save_params': False, 'embs_path': '../embs/', 'params_path': '../ckpt/', 'early_stopping': True, 'esc': 'error', 'verbose_early_stopping': False, 'disable_tqdm': False, 'valid_metric': 'mi_acc', 'learning_rate': 0.0001, 'batch_size': 512, 'valid_batch_size': 10000, 'num_epochs': 100, 'eval_freq': 1, 'patience': 20, 'device': device(type='cuda'), 'lambda': 9.972254466547545e-06, 'tensorboard': False, 'flush_freq': True, 'pred_metrics': ['mi_acc'], 'profile_metrics': ['meta_doa'], 'num_responses': 12, 'low_mem': False, 'n_query': 6, 'CDM': 'impact', 'i_fold': 0, 'num_inner_users_epochs': 3, 'num_inner_epochs': 10, 'inner_lr': 0.0001, 'inner_user_lr': 0.016848380924625605, 'meta_lr': 0.05, 'meta_trainer': 'Adam', 'num_workers': 0, 'pin_memory': False, 'debug': False, 'd_in': 4} ####\n"
     ]
    }
   ],
   "source": [
    "logging.info(f'#### {config[\"dataset_name\"]} ####')\n",
    "logging.info(f'#### config : {config} ####')\n",
    "config['embs_path']='../embs/'\n",
    "config['params_path']='../ckpt/'\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Dataset downloading for doa and rm\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in divide\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "## Concept map format : {question_id : [category_id1, category_id2, ...]}\n",
    "concept_map = json.load(open(f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_concept_map.json', 'r'))\n",
    "concept_map = {int(k): [int(x) for x in v] for k, v in concept_map.items()}\n",
    "\n",
    "## Metadata map format : {\"num_user_id\": ..., \"num_item_id\": ..., \"num_dimension_id\": ...}\n",
    "metadata = json.load(open(f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_metadata.json', 'r'))\n",
    "\n",
    "\n",
    "## Tensor containing the nb of modalities per question\n",
    "nb_modalities = torch.load(f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_nb_modalities.pkl',weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e868c02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto_index(d) : \n",
    "    d_acc = d[0]\n",
    "    d_meta = d[1]\n",
    "\n",
    "    r = []\n",
    "\n",
    "    for i in range(len(d_acc)):\n",
    "        r.append((0.5-d_acc[i]['mi_acc'])*(0.5-d_meta[i]['meta_doa']))\n",
    "    return sum(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "846a5c594351413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 36:20] #### meta_trainer : BETA-CD ####\n",
      "[INFO 36:20] #### i_fold : 0 ####\n",
      "[INFO 36:35] #### seed : 0 ####\n",
      "[INFO 36:35] Random_cont_model\n",
      "[INFO 36:35] compiling CDM model\n",
      "[INFO 36:38] compiling selection model\n",
      "[INFO 36:38] ------- START Training\n",
      "[INFO 36:38] train on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/liriscat/liriscat/selectionStrategy/random.py:30: UserWarning: get_params() Notimplemented\n",
      "  warnings.warn('get_params() Notimplemented')\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 36:38] ----- User batch : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/liriscat/liriscat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n",
      "  if getattr(p, \"grad\", None) is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 36:49] ----- User batch : 1\n",
      "[INFO 36:58] ----- User batch : 2\n",
      "[INFO 37:07] ----- User batch : 3\n",
      "[INFO 37:15] ----- User batch : 4\n",
      "[INFO 37:19] - user_mean: 0.05\n",
      "[INFO 37:19] - user_log_std: 0.05\n",
      "[INFO 37:19] - inner_lrs: 0.05\n",
      "[INFO 37:33] rmse : 0.5997521281242371\n",
      "[INFO 37:33] valid_rmse : 0.7669464349746704\n",
      "[INFO 37:33] valid_loss : 0.9467777609825134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:54<1:30:22, 54.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 37:33] ----- User batch : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/liriscat/liriscat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n",
      "  if getattr(p, \"grad\", None) is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 37:41] ----- User batch : 1\n",
      "[INFO 37:50] ----- User batch : 2\n",
      "[INFO 37:59] ----- User batch : 3\n",
      "[INFO 38:07] ----- User batch : 4\n",
      "[INFO 38:11] - user_mean: 0.05\n",
      "[INFO 38:11] - user_log_std: 0.05\n",
      "[INFO 38:11] - inner_lrs: 0.05\n",
      "[INFO 38:23] rmse : 0.6163620948791504\n",
      "[INFO 38:23] valid_rmse : 0.78818678855896\n",
      "[INFO 38:23] valid_loss : 0.9460064768791199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [01:44<1:24:49, 51.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 38:23] ----- User batch : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/liriscat/liriscat/meta_models/meta_models.py:70: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n",
      "  if getattr(p, \"grad\", None) is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 38:31] ----- User batch : 1\n",
      "[INFO 38:39] ----- User batch : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [02:08<1:44:54, 64.23s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     35\u001b[39m S = liriscat.selectionStrategy.Random(metadata,**config)\n\u001b[32m     36\u001b[39m S.init_models(train_data, valid_data)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43mS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m liriscat.utils.set_seed(\u001b[32m0\u001b[39m)\n\u001b[32m     39\u001b[39m S.reset_rng()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/liriscat/liriscat/selectionStrategy/abstract_selection_strategy.py:829\u001b[39m, in \u001b[36mAbstractSelectionStrategy.train\u001b[39m\u001b[34m(self, train_dataset, valid_dataset)\u001b[39m\n\u001b[32m    826\u001b[39m \u001b[38;5;28mself\u001b[39m.best_CDM_params = \u001b[38;5;28mself\u001b[39m.CDM.get_params()        \n\u001b[32m    828\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlearning_users_emb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[38;5;28mself\u001b[39m._trained = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    833\u001b[39m logging.info(\u001b[33m\"\u001b[39m\u001b[33m-- END Training --\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/liriscat/liriscat/selectionStrategy/abstract_selection_strategy.py:880\u001b[39m, in \u001b[36mAbstractSelectionStrategy._train_early_stopping_error\u001b[39m\u001b[34m(self, train_dataset, valid_dataset, learning_users_emb)\u001b[39m\n\u001b[32m    876\u001b[39m     learning_users_emb = torch.tile(\u001b[38;5;28mself\u001b[39m.learning_users_emb, (train_dataset.n_users, \u001b[32m1\u001b[39m)).to(\u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    878\u001b[39m mean_meta_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m880\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mu_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# UserCollate directly load the data into the query environment\u001b[39;49;00m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m----- User batch : \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mu_batch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_query_env\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/liriscat/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/liriscat/lib/python3.11/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/liriscat/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/liriscat/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/liriscat/liriscat/dataset/dataset.py:284\u001b[39m, in \u001b[36mCATDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[32m    280\u001b[39m     \u001b[38;5;66;03m# return the data of the user reindexed in this dataset instance\u001b[39;00m\n\u001b[32m    281\u001b[39m     \u001b[38;5;66;03m# Warning : index is not the user id but the index of the user in the dataset!\u001b[39;00m\n\u001b[32m    282\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mGenerates one sample of data\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/liriscat/liriscat/dataset/dataset.py:262\u001b[39m, in \u001b[36mCATDataset.generate_sample\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    258\u001b[39m mc_mask = \u001b[38;5;28mself\u001b[39m._mask_flat[idx_m].reshape(-\u001b[32m1\u001b[39m)\n\u001b[32m    259\u001b[39m mc_nb   = \u001b[38;5;28mself\u001b[39m.cat_nb[mq]\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mu_idx\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muser_idx2id\u001b[49m[index],     \u001b[38;5;66;03m# int\u001b[39;00m\n\u001b[32m    263\u001b[39m \n\u001b[32m    264\u001b[39m     \u001b[38;5;66;03m# Support set\u001b[39;00m\n\u001b[32m    265\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msq\u001b[39m\u001b[33m'\u001b[39m:   sq,        \u001b[38;5;66;03m# 1D torch.Tensor, size = Q_u,   where Q_u = data['q_ids'].size(0) - n_meta\u001b[39;00m\n\u001b[32m    266\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msl\u001b[39m\u001b[33m'\u001b[39m:   sl,        \u001b[38;5;66;03m# 1D torch.Tensor, size = Q_u\u001b[39;00m\n\u001b[32m    267\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msc\u001b[39m\u001b[33m'\u001b[39m:   sc,        \u001b[38;5;66;03m# 1D torch.Tensor, size = Q_u * cq_max\u001b[39;00m\n\u001b[32m    268\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msc_mask\u001b[39m\u001b[33m'\u001b[39m: sc_mask,\u001b[38;5;66;03m# 1D torch.Tensor, size = Q_u * cq_max\u001b[39;00m\n\u001b[32m    269\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msc_nb\u001b[39m\u001b[33m'\u001b[39m:   sc_nb,  \u001b[38;5;66;03m# 1D torch.Tensor, size = Q_u\u001b[39;00m\n\u001b[32m    270\u001b[39m \n\u001b[32m    271\u001b[39m     \u001b[38;5;66;03m# Meta set\u001b[39;00m\n\u001b[32m    272\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmq\u001b[39m\u001b[33m'\u001b[39m:   mq,        \u001b[38;5;66;03m# 1D torch.Tensor, size = M,     where M = n_meta\u001b[39;00m\n\u001b[32m    273\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mml\u001b[39m\u001b[33m'\u001b[39m:   ml,        \u001b[38;5;66;03m# 1D torch.Tensor, size = M\u001b[39;00m\n\u001b[32m    274\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmc\u001b[39m\u001b[33m'\u001b[39m:   mc,        \u001b[38;5;66;03m# 1D torch.Tensor, size = M * cq_max\u001b[39;00m\n\u001b[32m    275\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmc_mask\u001b[39m\u001b[33m'\u001b[39m: mc_mask,\u001b[38;5;66;03m# 1D torch.Tensor, size = M * cq_max\u001b[39;00m\n\u001b[32m    276\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmc_nb\u001b[39m\u001b[33m'\u001b[39m:   mc_nb   \u001b[38;5;66;03m# 1D torch.Tensor, size = M\u001b[39;00m\n\u001b[32m    277\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/liriscat/liriscat/dataset/dataset.py:148\u001b[39m, in \u001b[36mDataset.user_idx2id\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34muser_id2idx\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._user_id2idx\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34muser_idx2id\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._user_idx2id\n\u001b[32m    152\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtorch_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "meta_trainers = ['BETA-CD']\n",
    "for meta_trainer in meta_trainers : \n",
    "    config['meta_trainer'] = meta_trainer\n",
    "    logging.info(f'#### meta_trainer : {config[\"meta_trainer\"]} ####')\n",
    "    for i_fold in range(1) : \n",
    "        config['i_fold'] = i_fold\n",
    "            \n",
    "        logging.info(f'#### i_fold : {i_fold} ####')\n",
    "        ## Dataframe columns : (user_id, question_id, response, category_id)\n",
    "        train_df = pd.read_csv(\n",
    "            f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_train_{i_fold}.csv',\n",
    "            encoding='utf-8', dtype={'student_id': int, 'item_id': int, \"correct\": float,\n",
    "                                                                    \"dimension_id\": int})\n",
    "        valid_df = pd.read_csv(\n",
    "            f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_valid_{i_fold}.csv',\n",
    "            encoding='utf-8', dtype={'student_id': int, 'item_id': int, \"correct\": float,\n",
    "                                                                    \"dimension_id\": int})\n",
    "        test_df = pd.read_csv(\n",
    "            f'../datasets/2-preprocessed_data/{config[\"dataset_name\"]}_test_{i_fold}.csv',\n",
    "            encoding='utf-8', dtype={'student_id': int, 'item_id': int, \"correct\": float,\n",
    "                                                                    \"dimension_id\": int})\n",
    "\n",
    "        train_data = liriscat.dataset.CATDataset(train_df, concept_map, metadata, config,nb_modalities)\n",
    "        valid_data = liriscat.dataset.EvalDataset(valid_df, concept_map, metadata, config,nb_modalities)\n",
    "        test_data = liriscat.dataset.EvalDataset(test_df, concept_map, metadata, config,nb_modalities)\n",
    "\n",
    "        for seed in range(1) :\n",
    "            config['seed'] = seed\n",
    "            logging.info(f'#### seed : {seed} ####')\n",
    "\n",
    "            train_data.reset_rng()\n",
    "            valid_data.reset_rng()\n",
    "            test_data.reset_rng()\n",
    "\n",
    "            S = liriscat.selectionStrategy.Random(metadata,**config)\n",
    "            S.init_models(train_data, valid_data)\n",
    "            S.train(train_data, valid_data)\n",
    "            liriscat.utils.set_seed(0)\n",
    "            S.reset_rng()\n",
    "            d = (S.evaluate_test(test_data, train_data, valid_data))\n",
    "            logging.info(d)\n",
    "            logging.info(pareto_index(d))\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (liriscat no frozen)",
   "language": "python",
   "name": "liriscat-nofrozen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
