{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f91591122382be0",
   "metadata": {},
   "source": [
    "# postcovid dataset preprocessing\n",
    "### Import"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train IMPACT model",
   "id": "b2aae2e1e426b88d"
  },
  {
   "cell_type": "code",
   "id": "a33306919a97d5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:24:44.002502Z",
     "start_time": "2025-04-17T13:24:43.981106Z"
    }
   },
   "source": [
    "from liriscat.utils import generate_eval_config\n",
    "import json\n",
    "from IMPACT.dataset import LoaderDataset as IMPACT_dataset\n",
    "from liriscat.CDM import *\n",
    "from IMPACT import model\n",
    "from liriscat.dataset.preprocessing_utilities import *\n",
    "\n",
    "\n",
    "folds_nb = 5\n",
    "dataset_name=\"postcovid\"\n",
    "\n",
    "# Set all the required parameters ---------------\n",
    "IMPACT_config = generate_eval_config(num_epochs=200, save_params=True, dataset_name=dataset_name, embs_path=\"../../embs/\"+dataset_name, params_path=\"../../ckpt/\"+dataset_name,  learning_rate=0.01885, lambda_=2e-7, batch_size=2048,valid_metric='mi_acc', pred_metrics=[\"mi_acc\"])\n",
    "\n",
    "concept_map = json.load(open(f'../2-preprocessed_data/{IMPACT_config[\"dataset_name\"]}_concept_map.json', 'r'))\n",
    "concept_map = {int(k): [int(x) for x in v] for k, v in concept_map.items()}\n",
    "#parameter\n",
    "metadata = json.load(open(f'../2-preprocessed_data/{IMPACT_config[\"dataset_name\"]}_metadata.json', 'r'))\n",
    "nb_modalities = torch.load(f'../2-preprocessed_data/{IMPACT_config[\"dataset_name\"]}_nb_modalities.pkl',weights_only=True)\n",
    "\n",
    "# Conversion helper that builds a DataFrame with specific dtypes and returns records.\n",
    "def convert_to_records(data):\n",
    "    df = pd.DataFrame(data, columns={'user_id': int, 'item_id': int, 'category_id': int,'correct': float, })\n",
    "    return df.to_records(index=False, column_dtypes={'user_id': int, 'item_id': int, 'correct': float, 'category_id': int})"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Using CPU.\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "id": "57f46a6fa28b0de3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:30:03.836263Z",
     "start_time": "2025-04-17T13:24:46.382703Z"
    }
   },
   "source": [
    "dataset_name = 'postcovid'\n",
    "for i in range(folds_nb):\n",
    "\n",
    "    train = pd.read_csv(\n",
    "    f'../2-preprocessed_data/{dataset_name}_train_{i_fold}.csv',\n",
    "    encoding='utf-8', dtype={'student_id': int, 'item_id': int, \"correct\": float,\n",
    "                                                             \"dimension_id\": int})\n",
    "    valid= pd.read_csv(\n",
    "    f'../2-preprocessed_data/{dataset_name}_valid_{i_fold}.csv',\n",
    "    encoding='utf-8', dtype={'student_id': int, 'item_id': int, \"correct\": float,\n",
    "                                                             \"dimension_id\": int})\n",
    "    # Merge the training and validation data for the current fold.\n",
    "    train_valid_df = pd.concat([train, valid])\n",
    "    # Split the merged data horizontally into train and validation sets.\n",
    "\n",
    "    quadruplet = quadruplet_format(train_valid_df)\n",
    "    train_data, valid_data, test_data = split_data_vertically(quadruplet, test_prop=0.2,valid_prop=0.1,folds_nb=5)\n",
    "\n",
    "    # Convert each split in one step using the helper.\n",
    "    horizontal_train = convert_to_records(train_data[0])\n",
    "    horizontal_valid = convert_to_records(valid_data[0])\n",
    "    horizontal_test = convert_to_records(test_data[0])\n",
    "\n",
    "    impact_train_data = IMPACT_dataset(horizontal_train, concept_map, metadata, nb_modalities)\n",
    "    impact_valid_data = IMPACT_dataset(horizontal_valid, concept_map, metadata, nb_modalities) # <---\n",
    "    impact_test_data = IMPACT_dataset(horizontal_test, concept_map, metadata, nb_modalities)\n",
    "\n",
    "    IMPACT_config['i_fold'] = i\n",
    "    algo = model.IMPACT(**IMPACT_config)\n",
    "    algo.init_model(impact_train_data, impact_valid_data)\n",
    "    algo.train(impact_train_data, impact_valid_data)\n",
    "    print(algo.evaluate_predictions(impact_test_data))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Skipping CUDA seed setting.\n",
      "[INFO 24-50] train on cpu\n",
      "[INFO 24-50] -- START Training --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 121/200 [01:03<00:41,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 25-53] -- END Training --\n",
      "[INFO 25-53] Params saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mi_acc': 0.8395308256149292, 'preds': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float64), 'labels': tensor([1., 1., 1.,  ..., 2., 1., 1.], dtype=torch.float64)}\n",
      "CUDA is not available. Skipping CUDA seed setting.\n",
      "[INFO 25-57] train on cpu\n",
      "[INFO 25-57] -- START Training --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 121/200 [00:58<00:38,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 26-56] -- END Training --\n",
      "[INFO 26-56] Params saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mi_acc': 0.8395308256149292, 'preds': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float64), 'labels': tensor([1., 1., 1.,  ..., 2., 1., 1.], dtype=torch.float64)}\n",
      "CUDA is not available. Skipping CUDA seed setting.\n",
      "[INFO 27-00] train on cpu\n",
      "[INFO 27-00] -- START Training --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 121/200 [00:58<00:37,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 27-58] -- END Training --\n",
      "[INFO 27-58] Params saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mi_acc': 0.8395308256149292, 'preds': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float64), 'labels': tensor([1., 1., 1.,  ..., 2., 1., 1.], dtype=torch.float64)}\n",
      "CUDA is not available. Skipping CUDA seed setting.\n",
      "[INFO 28-02] train on cpu\n",
      "[INFO 28-02] -- START Training --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 121/200 [00:58<00:38,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 29-01] -- END Training --\n",
      "[INFO 29-01] Params saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mi_acc': 0.8395308256149292, 'preds': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float64), 'labels': tensor([1., 1., 1.,  ..., 2., 1., 1.], dtype=torch.float64)}\n",
      "CUDA is not available. Skipping CUDA seed setting.\n",
      "[INFO 29-05] train on cpu\n",
      "[INFO 29-05] -- START Training --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 121/200 [00:58<00:38,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 30-03] -- END Training --\n",
      "[INFO 30-03] Params saved\n",
      "{'mi_acc': 0.8395308256149292, 'preds': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float64), 'labels': tensor([1., 1., 1.,  ..., 2., 1., 1.], dtype=torch.float64)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:51:09.635620Z",
     "start_time": "2025-04-17T11:51:07.769585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "quadruplet = quadruplet_format(train_valid_df)\n",
    "\n",
    "valid_prop=0.1\n",
    "\n",
    "df = pd.DataFrame(quadruplet, columns=[\"student_id\", \"item_id\", \"answer\", \"dimension_id\"])\n",
    "df.columns = [\"student_id\",\"item_id\",\"answer\",\"dimension_id\"]\n",
    "df.head()\n",
    "df_grouped = df.groupby(['student_id', 'item_id']).agg(\n",
    "    answers=('answer', list),\n",
    "    dimensions=('dimension_id', list)\n",
    ").reset_index()\n",
    "\n",
    "#method of sci_ski_learn\n",
    "\n",
    "for i_group, group in df_grouped.groupby('student_id'):\n",
    "    group_idxs = np.array(group.index)\n",
    "    train, valid = train_test_split(df_grouped, test_size=valid_prop, shuffle=True)\n",
    "print(\"\\nTraining set:\")\n",
    "print(train)\n",
    "\n",
    "print(\"\\nValidation set :\")\n",
    "print(valid)\n",
    "\n",
    "train_expanded = train.explode(['answers', 'dimensions'])\n",
    "valid_expanded = valid.explode(['answers', 'dimensions'])\n",
    "\n",
    "print(\"\\nTraining set after expanding :\")\n",
    "print(train_expanded)\n",
    "\n",
    "print(\"\\nValidation set after expanding :\")\n",
    "print(valid_expanded)"
   ],
   "id": "af1d7f9499eb7829",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set:\n",
      "       student_id  item_id                                            answers  \\\n",
      "11441         307      104                                              [1.0]   \n",
      "27404         739       41  [1.6666666666666663, 1.6666666666666663, 1.666...   \n",
      "2951           83        9                                              [1.0]   \n",
      "19594         516       95                                              [2.0]   \n",
      "11582         311       84                                              [1.5]   \n",
      "...           ...      ...                                                ...   \n",
      "18828         494       48  [1.6666666666666663, 1.6666666666666663, 1.666...   \n",
      "6022          160        5                               [1.6666666666666663]   \n",
      "17432         453       96                               [1.6666666666666663]   \n",
      "26975         732       33                                    [2.0, 2.0, 2.0]   \n",
      "11106         301        3                                              [2.0]   \n",
      "\n",
      "      dimensions  \n",
      "11441       [11]  \n",
      "27404  [6, 7, 8]  \n",
      "2951         [1]  \n",
      "19594       [11]  \n",
      "11582        [5]  \n",
      "...          ...  \n",
      "18828  [6, 7, 8]  \n",
      "6022         [0]  \n",
      "17432       [11]  \n",
      "26975  [6, 7, 8]  \n",
      "11106        [0]  \n",
      "\n",
      "[24921 rows x 4 columns]\n",
      "\n",
      "Validation set :\n",
      "       student_id  item_id               answers dimensions\n",
      "9209          246      107  [1.6666666666666663]       [11]\n",
      "5182          134       19                 [1.0]        [0]\n",
      "18393         481       32                 [1.5]        [5]\n",
      "12991         346        9                [1.25]        [1]\n",
      "23288         625      122                 [2.0]       [12]\n",
      "...           ...      ...                   ...        ...\n",
      "16158         419       49          [1.75, 1.75]    [9, 10]\n",
      "9826          260       82  [1.3333333333333333]        [3]\n",
      "20310         534        6                 [1.5]        [1]\n",
      "12469         333       31                [1.75]        [4]\n",
      "12212         324      132                 [1.0]       [13]\n",
      "\n",
      "[2769 rows x 4 columns]\n",
      "\n",
      "Training set after expanding :\n",
      "       student_id  item_id   answers dimensions\n",
      "11441         307      104       1.0         11\n",
      "27404         739       41  1.666667          6\n",
      "27404         739       41  1.666667          7\n",
      "27404         739       41  1.666667          8\n",
      "2951           83        9       1.0          1\n",
      "...           ...      ...       ...        ...\n",
      "17432         453       96  1.666667         11\n",
      "26975         732       33       2.0          6\n",
      "26975         732       33       2.0          7\n",
      "26975         732       33       2.0          8\n",
      "11106         301        3       2.0          0\n",
      "\n",
      "[35052 rows x 4 columns]\n",
      "\n",
      "Validation set after expanding :\n",
      "       student_id  item_id   answers dimensions\n",
      "9209          246      107  1.666667         11\n",
      "5182          134       19       1.0          0\n",
      "18393         481       32       1.5          5\n",
      "12991         346        9      1.25          1\n",
      "23288         625      122       2.0         12\n",
      "...           ...      ...       ...        ...\n",
      "16158         419       49      1.75         10\n",
      "9826          260       82  1.333333          3\n",
      "20310         534        6       1.5          1\n",
      "12469         333       31      1.75          4\n",
      "12212         324      132       1.0         13\n",
      "\n",
      "[3848 rows x 4 columns]\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:30:29.920227Z",
     "start_time": "2025-04-17T11:30:29.772607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "r_train = train_expanded.apply(lambda x : str(x['student_id']),axis=1).unique()\n",
    "r_valid= valid_expanded.apply(lambda x : str(x['student_id']),axis=1).unique()"
   ],
   "id": "c4a2ad6f6d73c090",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:30:33.211204Z",
     "start_time": "2025-04-17T11:30:33.191719Z"
    }
   },
   "cell_type": "code",
   "source": "set(r_train) - (set(r_valid))",
   "id": "aaaab388a0ae306d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'143',\n",
       " '189',\n",
       " '19',\n",
       " '234',\n",
       " '250',\n",
       " '29',\n",
       " '3',\n",
       " '321',\n",
       " '331',\n",
       " '361',\n",
       " '372',\n",
       " '4',\n",
       " '407',\n",
       " '422',\n",
       " '492',\n",
       " '535',\n",
       " '573',\n",
       " '574',\n",
       " '603',\n",
       " '61',\n",
       " '638',\n",
       " '663',\n",
       " '79'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T14:41:32.843283Z",
     "start_time": "2025-04-16T14:41:32.805345Z"
    }
   },
   "cell_type": "code",
   "source": "df_grouped.head()",
   "id": "dd913a4e29a16642",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   student_id  item_id               answers dimensions\n",
       "0           0        0  [1.3333333333333333]        [0]\n",
       "1           0        1                 [2.0]        [0]\n",
       "2           0        2  [1.6666666666666663]        [0]\n",
       "3           0        3                 [2.0]        [0]\n",
       "4           0        4  [1.3333333333333333]        [0]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>answers</th>\n",
       "      <th>dimensions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.3333333333333333]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.0]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.6666666666666663]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[2.0]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[1.3333333333333333]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:05:54.149799Z",
     "start_time": "2025-04-17T13:05:54.094010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge the training and validation data for the current fold.\n",
    "train_valid_df = pd.concat([train[i], valid[i]])\n",
    "# Split the merged data horizontally into train and validation sets.\n",
    "\n",
    "quadruplet = quadruplet_format(train_valid_df)\n",
    "train_data, valid_data, test_data = split_data_vertically(quadruplet, test_prop=0.2,valid_prop=0.1,folds_nb=5)"
   ],
   "id": "7338f51a5090aa33",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[63], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Merge the training and validation data for the current fold.\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m train_valid_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([train[i], valid[i]])\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Split the merged data horizontally into train and validation sets.\u001B[39;00m\n\u001B[1;32m      5\u001B[0m quadruplet \u001B[38;5;241m=\u001B[39m quadruplet_format(train_valid_df)\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mget_loc(key)\n\u001B[1;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3810\u001B[0m     ):\n\u001B[1;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 0"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "id": "688393a7-50ba-402c-bedd-a966bca887e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:36:39.747493Z",
     "start_time": "2025-04-16T12:36:38.057327Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "from liriscat import utils\n",
    "utils.set_seed(0)\n",
    "from liriscat import dataset\n",
    "from liriscat import selectionStrategy\n",
    "from liriscat import CDM\n",
    "\n",
    "import logging\n",
    "import gc\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "import IMPACT\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "reload(utils)\n",
    "reload(selectionStrategy)\n",
    "reload(CDM)\n",
    "reload(dataset)\n",
    "\n",
    "config = utils.generate_eval_config(i_fold = 0,\n",
    "                                    num_epochs=1,\n",
    "                                    load_params=True,\n",
    "                                    inner_user_lr=0.0001,\n",
    "                                    esc = 'error',\n",
    "                                    valid_metric= 'mi_acc',\n",
    "                                    pred_metrics = [\"mi_acc\"],\n",
    "                                    profile_metrics = ['doa'],\n",
    "                                    save_params=False,\n",
    "                                    n_query=5,\n",
    "                                    batch_size=512)\n",
    "utils.set_seed(config[\"seed\"])\n",
    "\n",
    "config[\"dataset_name\"] = \"postcovid\"\n",
    "logging.info(config[\"dataset_name\"])\n",
    "config['learning_rate'] = 0.02026\n",
    "config['lambda'] = 1.2e-5\n",
    "config['d_in'] = 4\n",
    "config['num_responses'] = 12\n",
    "#pred_metrics,df_interp = test(config)\n",
    "\n",
    "logging.info(f'#### {config[\"dataset_name\"]} ####')\n",
    "logging.info(f'#### config : {config} ####')\n",
    "config['embs_path']='../../embs/'+str(config[\"dataset_name\"])\n",
    "config['params_path']='../../ckpt/'+str(config[\"dataset_name\"])\n",
    "\n",
    "pred_metrics = {m:[] for m in config['pred_metrics']}\n",
    "profile_metrics = {m:[] for m in config['profile_metrics']}\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Dataset downloading for doa and rm\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in divide\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "## Concept map format : {question_id : [category_id1, category_id2, ...]}outside model initialization\n",
    "concept_map = json.load(open(f'../2-preprocessed_data/{config[\"dataset_name\"]}_concept_map.json', 'r'))\n",
    "concept_map = {int(k): [int(x) for x in v] for k, v in concept_map.items()}\n",
    "\n",
    "## Metadata map format : {\"num_user_id\": ..., \"num_item_id\": ..., \"num_dimension_id\": ...}\n",
    "metadata = json.load(open(f'../2-preprocessed_data/{config[\"dataset_name\"]}_metadata.json', 'r'))\n",
    "\n",
    "i_fold = 0\n",
    "## Dataframe columns : (user_id, question_id, response, category_id)\n",
    "train_df = pd.read_csv(\n",
    "    f'../2-preprocessed_data/{config[\"dataset_name\"]}_train_{i_fold}.csv',\n",
    "    encoding='utf-8', dtype={'student_id': int, 'item_id': int, \"correct\": float,\n",
    "                                                             \"dimension_id\": int})\n",
    "valid_df = pd.read_csv(\n",
    "    f'../2-preprocessed_data/{config[\"dataset_name\"]}_valid_{i_fold}.csv',\n",
    "    encoding='utf-8', dtype={'student_id': int, 'item_id': int, \"correct\": float,\n",
    "                                                             \"dimension_id\": int})\n",
    "test_df = pd.read_csv(\n",
    "    f'../2-preprocessed_data/{config[\"dataset_name\"]}_test_{i_fold}.csv',\n",
    "    encoding='utf-8', dtype={'student_id': int, 'item_id': int, \"correct\": float,\n",
    "                                                             \"dimension_id\": int})\n",
    "train_data = dataset.CATDataset(train_df, concept_map, metadata, config, nb_modalities)\n",
    "valid_data = dataset.EvalDataset(valid_df, concept_map, metadata, config, nb_modalities)\n",
    "test_data = dataset.EvalDataset(test_df, concept_map, metadata, config, nb_modalities)\n",
    "\n",
    "S = selectionStrategy.Random(metadata,**config)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Skipping CUDA seed setting.\n",
      "CUDA is not available. Using CPU.\n",
      "CUDA is not available. Skipping CUDA seed setting.\n",
      "[INFO 36-38] postcovid\n",
      "[INFO 36-38] #### postcovid ####\n",
      "[INFO 36-38] #### config : {'seed': 0, 'dataset_name': 'postcovid', 'load_params': True, 'save_params': False, 'embs_path': '../embs/', 'params_path': '../ckpt/', 'early_stopping': True, 'esc': 'error', 'verbose_early_stopping': False, 'disable_tqdm': False, 'valid_metric': 'mi_acc', 'learning_rate': 0.02026, 'batch_size': 512, 'valid_batch_size': 10000, 'num_epochs': 1, 'eval_freq': 1, 'patience': 30, 'device': device(type='cpu'), 'lambda': 1.2e-05, 'tensorboard': False, 'flush_freq': True, 'pred_metrics': ['mi_acc'], 'profile_metrics': ['doa'], 'num_responses': 12, 'low_mem': False, 'n_query': 5, 'CDM': 'impact', 'i_fold': 0, 'num_inner_users_epochs': 10, 'num_inner_epochs': 10, 'inner_lr': 0.0001, 'inner_user_lr': 0.0001, 'd_in': 4} ####\n",
      "CUDA is not available. Skipping CUDA seed setting.\n",
      "CUDA is not available. Skipping CUDA seed setting.\n",
      "[INFO 36-39] Random_cont_model\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "b490a908-2265-44f3-854a-59166b199f23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:36:43.157646Z",
     "start_time": "2025-04-16T12:36:42.446435Z"
    }
   },
   "source": [
    "S.init_models(train_data, valid_data)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling CDM model\n",
      "compiling selection model\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "a5f95c28-dd26-4460-ba12-27a9cbf79f17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:36:52.132855Z",
     "start_time": "2025-04-16T12:36:46.473583Z"
    }
   },
   "source": [
    "S.evaluate_test(test_data)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbensafi/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "  0%|          | 0/5 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "BackendCompilerFailed",
     "evalue": "backend='inductor' raised:\nInvalidCxxCompiler: No working C++ compiler found in torch._inductor.config.cpp.cxx: (None, 'g++')\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mBackendCompilerFailed\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[33], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m S\u001B[38;5;241m.\u001B[39mevaluate_test(test_data)\n",
      "File \u001B[0;32m~/PycharmProjects/liriscat/liriscat/selectionStrategy/abstract_selection_strategy.py:142\u001B[0m, in \u001B[0;36mAbstractSelectionStrategy.evaluation_state.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39meval() \u001B[38;5;66;03m# todo : putting in eval mode again\u001B[39;00m\n\u001B[1;32m    141\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad(), torch\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mautocast(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m--> 142\u001B[0m         result \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    144\u001B[0m     \u001B[38;5;66;03m# Restore the previous state after method execution\u001B[39;00m\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mCDM\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[0;32m~/PycharmProjects/liriscat/liriscat/selectionStrategy/abstract_selection_strategy.py:233\u001B[0m, in \u001B[0;36mAbstractSelectionStrategy.evaluate_test\u001B[0;34m(self, test_dataset)\u001B[0m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39menable_grad():\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mCDM\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m--> 233\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mCDM\u001B[38;5;241m.\u001B[39mupdate_users(test_query_env\u001B[38;5;241m.\u001B[39mfeed_IMPACT_sub(),(m_user_ids, m_question_ids, m_category_ids),m_labels)\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mCDM\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m    237\u001B[0m preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mCDM\u001B[38;5;241m.\u001B[39mmodel(m_user_ids, m_question_ids, m_category_ids)\n",
      "File \u001B[0;32m~/PycharmProjects/liriscat/liriscat/CDM/IMPACT.py:98\u001B[0m, in \u001B[0;36mCATIMPACT.update_users\u001B[0;34m(self, query_data, meta_data, meta_labels)\u001B[0m\n\u001B[1;32m     95\u001B[0m labels \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     96\u001B[0m category_ids \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcategory_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m---> 98\u001B[0m preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(m_user_ids, m_question_ids, m_category_ids)\n\u001B[1;32m    100\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmeta mi_acc = \u001B[39m\u001B[38;5;124m\"\u001B[39m, utils\u001B[38;5;241m.\u001B[39mmicro_ave_accuracy(meta_labels, preds))\n\u001B[1;32m    102\u001B[0m user_params_optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:574\u001B[0m, in \u001B[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    569\u001B[0m saved_dynamic_layer_stack_depth \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    570\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_functorch\u001B[38;5;241m.\u001B[39mget_dynamic_layer_stack_depth()\n\u001B[1;32m    571\u001B[0m )\n\u001B[1;32m    573\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 574\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    575\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    576\u001B[0m     \u001B[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001B[39;00m\n\u001B[1;32m    577\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_functorch\u001B[38;5;241m.\u001B[39mpop_dynamic_layer_stack_and_undo_to_depth(\n\u001B[1;32m    578\u001B[0m         saved_dynamic_layer_stack_depth\n\u001B[1;32m    579\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1380\u001B[0m, in \u001B[0;36mCatchErrorsWrapper.__call__\u001B[0;34m(self, frame, cache_entry, frame_state)\u001B[0m\n\u001B[1;32m   1374\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m hijacked_callback(\n\u001B[1;32m   1375\u001B[0m                 frame, cache_entry, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhooks, frame_state\n\u001B[1;32m   1376\u001B[0m             )\n\u001B[1;32m   1378\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m compile_lock, _disable_current_modes():\n\u001B[1;32m   1379\u001B[0m     \u001B[38;5;66;03m# skip=1: skip this frame\u001B[39;00m\n\u001B[0;32m-> 1380\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_torchdynamo_orig_callable(\n\u001B[1;32m   1381\u001B[0m         frame, cache_entry, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhooks, frame_state, skip\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1382\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1164\u001B[0m, in \u001B[0;36mConvertFrame.__call__\u001B[0;34m(self, frame, cache_entry, hooks, frame_state, skip)\u001B[0m\n\u001B[1;32m   1162\u001B[0m counters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mframes\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtotal\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1163\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1164\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inner_convert(\n\u001B[1;32m   1165\u001B[0m         frame, cache_entry, hooks, frame_state, skip\u001B[38;5;241m=\u001B[39mskip \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1166\u001B[0m     )\n\u001B[1;32m   1167\u001B[0m     counters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mframes\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mok\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1168\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:547\u001B[0m, in \u001B[0;36mConvertFrameAssert.__call__\u001B[0;34m(self, frame, cache_entry, hooks, frame_state, skip)\u001B[0m\n\u001B[1;32m    544\u001B[0m     dynamo_tls\u001B[38;5;241m.\u001B[39mtraced_frame_infos\u001B[38;5;241m.\u001B[39mappend(info)\n\u001B[1;32m    546\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m compile_context(CompileContext(compile_id)):\n\u001B[0;32m--> 547\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _compile(\n\u001B[1;32m    548\u001B[0m         frame\u001B[38;5;241m.\u001B[39mf_code,\n\u001B[1;32m    549\u001B[0m         frame\u001B[38;5;241m.\u001B[39mf_globals,\n\u001B[1;32m    550\u001B[0m         frame\u001B[38;5;241m.\u001B[39mf_locals,\n\u001B[1;32m    551\u001B[0m         frame\u001B[38;5;241m.\u001B[39mf_builtins,\n\u001B[1;32m    552\u001B[0m         frame\u001B[38;5;241m.\u001B[39mclosure,\n\u001B[1;32m    553\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_torchdynamo_orig_callable,\n\u001B[1;32m    554\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_one_graph,\n\u001B[1;32m    555\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_export,\n\u001B[1;32m    556\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_export_constraints,\n\u001B[1;32m    557\u001B[0m         hooks,\n\u001B[1;32m    558\u001B[0m         cache_entry,\n\u001B[1;32m    559\u001B[0m         cache_size,\n\u001B[1;32m    560\u001B[0m         frame,\n\u001B[1;32m    561\u001B[0m         frame_state\u001B[38;5;241m=\u001B[39mframe_state,\n\u001B[1;32m    562\u001B[0m         compile_id\u001B[38;5;241m=\u001B[39mcompile_id,\n\u001B[1;32m    563\u001B[0m         skip\u001B[38;5;241m=\u001B[39mskip \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m    564\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:986\u001B[0m, in \u001B[0;36m_compile\u001B[0;34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip)\u001B[0m\n\u001B[1;32m    984\u001B[0m guarded_code \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    985\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 986\u001B[0m     guarded_code \u001B[38;5;241m=\u001B[39m compile_inner(code, one_graph, hooks, transform)\n\u001B[1;32m    988\u001B[0m     \u001B[38;5;66;03m# NB: We only put_code_state in success case.  Success case here\u001B[39;00m\n\u001B[1;32m    989\u001B[0m     \u001B[38;5;66;03m# does include graph breaks; specifically, if a graph break still\u001B[39;00m\n\u001B[1;32m    990\u001B[0m     \u001B[38;5;66;03m# resulted in a partially compiled graph, we WILL return here.  An\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    995\u001B[0m     \u001B[38;5;66;03m# to upload for graph break though, because this can prevent\u001B[39;00m\n\u001B[1;32m    996\u001B[0m     \u001B[38;5;66;03m# extra graph break compilations.)\u001B[39;00m\n\u001B[1;32m    997\u001B[0m     put_code_state()\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:715\u001B[0m, in \u001B[0;36m_compile.<locals>.compile_inner\u001B[0;34m(code, one_graph, hooks, transform)\u001B[0m\n\u001B[1;32m    713\u001B[0m     stack\u001B[38;5;241m.\u001B[39menter_context(torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39minstall_callbacks())\n\u001B[1;32m    714\u001B[0m     stack\u001B[38;5;241m.\u001B[39menter_context(CompileTimeInstructionCounter\u001B[38;5;241m.\u001B[39mrecord())\n\u001B[0;32m--> 715\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _compile_inner(code, one_graph, hooks, transform)\n\u001B[1;32m    717\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_utils_internal.py:95\u001B[0m, in \u001B[0;36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     92\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m skip \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m StrobelightCompileTimeProfiler\u001B[38;5;241m.\u001B[39menabled:\n\u001B[0;32m---> 95\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m function(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m StrobelightCompileTimeProfiler\u001B[38;5;241m.\u001B[39mprofile_compile_time(\n\u001B[1;32m     98\u001B[0m     function, phase_name, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m     99\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:750\u001B[0m, in \u001B[0;36m_compile.<locals>._compile_inner\u001B[0;34m(code, one_graph, hooks, transform)\u001B[0m\n\u001B[1;32m    748\u001B[0m CompileContext\u001B[38;5;241m.\u001B[39mget()\u001B[38;5;241m.\u001B[39mattempt \u001B[38;5;241m=\u001B[39m attempt\n\u001B[1;32m    749\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 750\u001B[0m     out_code \u001B[38;5;241m=\u001B[39m transform_code_object(code, transform)\n\u001B[1;32m    751\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    752\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m exc\u001B[38;5;241m.\u001B[39mRestartAnalysis \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py:1361\u001B[0m, in \u001B[0;36mtransform_code_object\u001B[0;34m(code, transformations, safe)\u001B[0m\n\u001B[1;32m   1358\u001B[0m instructions \u001B[38;5;241m=\u001B[39m cleaned_instructions(code, safe)\n\u001B[1;32m   1359\u001B[0m propagate_line_nums(instructions)\n\u001B[0;32m-> 1361\u001B[0m transformations(instructions, code_options)\n\u001B[1;32m   1362\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:231\u001B[0m, in \u001B[0;36mpreserve_global_state.<locals>._fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    229\u001B[0m exit_stack\u001B[38;5;241m.\u001B[39menter_context(torch_function_mode_stack_state_mgr)\n\u001B[1;32m    230\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 231\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    233\u001B[0m     cleanup\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:662\u001B[0m, in \u001B[0;36m_compile.<locals>.transform\u001B[0;34m(instructions, code_options)\u001B[0m\n\u001B[1;32m    660\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    661\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tracing(tracer\u001B[38;5;241m.\u001B[39moutput\u001B[38;5;241m.\u001B[39mtracing_context), tracer\u001B[38;5;241m.\u001B[39mset_current_tx():\n\u001B[0;32m--> 662\u001B[0m         tracer\u001B[38;5;241m.\u001B[39mrun()\n\u001B[1;32m    663\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m exc\u001B[38;5;241m.\u001B[39mUnspecializeRestartAnalysis:\n\u001B[1;32m    664\u001B[0m     speculation_log\u001B[38;5;241m.\u001B[39mclear()\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2868\u001B[0m, in \u001B[0;36mInstructionTranslator.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2867\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m-> 2868\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrun()\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1052\u001B[0m, in \u001B[0;36mInstructionTranslatorBase.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1050\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1051\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput\u001B[38;5;241m.\u001B[39mpush_tx(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m-> 1052\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep():\n\u001B[1;32m   1053\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m   1054\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m TensorifyScalarRestartAnalysis:\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:962\u001B[0m, in \u001B[0;36mInstructionTranslatorBase.step\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    959\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate_block_stack(inst)\n\u001B[1;32m    961\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 962\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_table[inst\u001B[38;5;241m.\u001B[39mopcode](\u001B[38;5;28mself\u001B[39m, inst)\n\u001B[1;32m    963\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput\u001B[38;5;241m.\u001B[39mshould_exit\n\u001B[1;32m    964\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m TensorifyScalarRestartAnalysis:\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:3048\u001B[0m, in \u001B[0;36mInstructionTranslator.RETURN_VALUE\u001B[0;34m(self, inst)\u001B[0m\n\u001B[1;32m   3047\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mRETURN_VALUE\u001B[39m(\u001B[38;5;28mself\u001B[39m, inst):\n\u001B[0;32m-> 3048\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_return(inst)\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:3033\u001B[0m, in \u001B[0;36mInstructionTranslator._return\u001B[0;34m(self, inst)\u001B[0m\n\u001B[1;32m   3028\u001B[0m _step_logger()(\n\u001B[1;32m   3029\u001B[0m     logging\u001B[38;5;241m.\u001B[39mINFO,\n\u001B[1;32m   3030\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorchdynamo done tracing \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_code\u001B[38;5;241m.\u001B[39mco_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00minst\u001B[38;5;241m.\u001B[39mopname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   3031\u001B[0m )\n\u001B[1;32m   3032\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m triggered compile\u001B[39m\u001B[38;5;124m\"\u001B[39m, inst\u001B[38;5;241m.\u001B[39mopname)\n\u001B[0;32m-> 3033\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput\u001B[38;5;241m.\u001B[39mcompile_subgraph(\n\u001B[1;32m   3034\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   3035\u001B[0m     reason\u001B[38;5;241m=\u001B[39mGraphCompileReason(\n\u001B[1;32m   3036\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreturn_value\u001B[39m\u001B[38;5;124m\"\u001B[39m, [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframe_summary()], graph_break\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   3037\u001B[0m     ),\n\u001B[1;32m   3038\u001B[0m )\n\u001B[1;32m   3039\u001B[0m return_inst \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   3040\u001B[0m     create_instruction(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRETURN_VALUE\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   3041\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m inst\u001B[38;5;241m.\u001B[39mopname \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRETURN_VALUE\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3042\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m create_instruction(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRETURN_CONST\u001B[39m\u001B[38;5;124m\"\u001B[39m, argval\u001B[38;5;241m=\u001B[39minst\u001B[38;5;241m.\u001B[39margval)\n\u001B[1;32m   3043\u001B[0m )\n\u001B[1;32m   3044\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput\u001B[38;5;241m.\u001B[39madd_output_instructions([return_inst])\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1101\u001B[0m, in \u001B[0;36mOutputGraph.compile_subgraph\u001B[0;34m(self, tx, partial_convert, reason)\u001B[0m\n\u001B[1;32m   1098\u001B[0m append_prefix_insts()\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# optimization to generate better code in a common case\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_output_instructions(\n\u001B[0;32m-> 1101\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompile_and_call_fx_graph(\n\u001B[1;32m   1102\u001B[0m         tx, \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mreversed\u001B[39m(stack_values)), root, output_replacements\n\u001B[1;32m   1103\u001B[0m     )\n\u001B[1;32m   1104\u001B[0m     \u001B[38;5;241m+\u001B[39m [create_instruction(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUNPACK_SEQUENCE\u001B[39m\u001B[38;5;124m\"\u001B[39m, arg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(stack_values))]\n\u001B[1;32m   1105\u001B[0m )\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;66;03m# restore all the live local vars\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_output_instructions(\n\u001B[1;32m   1108\u001B[0m     [\n\u001B[1;32m   1109\u001B[0m         PyCodegen(tx, overridden_sources\u001B[38;5;241m=\u001B[39moverridden_sources)\u001B[38;5;241m.\u001B[39mcreate_store(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1113\u001B[0m     ]\n\u001B[1;32m   1114\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1382\u001B[0m, in \u001B[0;36mOutputGraph.compile_and_call_fx_graph\u001B[0;34m(self, tx, rv, root, replaced_outputs)\u001B[0m\n\u001B[1;32m   1379\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtracing_context\u001B[38;5;241m.\u001B[39mfake_mode \u001B[38;5;241m=\u001B[39m backend_fake_mode\n\u001B[1;32m   1381\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrestore_global_state():\n\u001B[0;32m-> 1382\u001B[0m     compiled_fn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcall_user_compiler(gm)\n\u001B[1;32m   1384\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_lazy_graph_module\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _LazyGraphModule\n\u001B[1;32m   1386\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(compiled_fn, _LazyGraphModule) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   1387\u001B[0m     \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mgetattr\u001B[39m(compiled_fn, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__self__\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m), _LazyGraphModule)\n\u001B[1;32m   1388\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m compiled_fn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_lazy_forward\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1392\u001B[0m     \u001B[38;5;66;03m# this is a _LazyGraphModule. This makes it easier for dynamo to\u001B[39;00m\n\u001B[1;32m   1393\u001B[0m     \u001B[38;5;66;03m# optimize a _LazyGraphModule.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1432\u001B[0m, in \u001B[0;36mOutputGraph.call_user_compiler\u001B[0;34m(self, gm)\u001B[0m\n\u001B[1;32m   1425\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcall_user_compiler\u001B[39m(\u001B[38;5;28mself\u001B[39m, gm: fx\u001B[38;5;241m.\u001B[39mGraphModule) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m CompiledFn:\n\u001B[1;32m   1426\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m dynamo_timed(\n\u001B[1;32m   1427\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOutputGraph.call_user_compiler\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1428\u001B[0m         phase_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbackend_compile\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1429\u001B[0m         log_pt2_compile_event\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m   1430\u001B[0m         dynamo_compile_column_us\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maot_autograd_cumulative_compile_time_us\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1431\u001B[0m     ):\n\u001B[0;32m-> 1432\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_user_compiler(gm)\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1483\u001B[0m, in \u001B[0;36mOutputGraph._call_user_compiler\u001B[0;34m(self, gm)\u001B[0m\n\u001B[1;32m   1481\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m   1482\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m-> 1483\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m BackendCompilerFailed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompiler_fn, e)\u001B[38;5;241m.\u001B[39mwith_traceback(\n\u001B[1;32m   1484\u001B[0m         e\u001B[38;5;241m.\u001B[39m__traceback__\n\u001B[1;32m   1485\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1487\u001B[0m signpost_event(\n\u001B[1;32m   1488\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdynamo\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1489\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOutputGraph.call_user_compiler\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1495\u001B[0m     },\n\u001B[1;32m   1496\u001B[0m )\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m compiled_fn\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1462\u001B[0m, in \u001B[0;36mOutputGraph._call_user_compiler\u001B[0;34m(self, gm)\u001B[0m\n\u001B[1;32m   1460\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mverify_correctness:\n\u001B[1;32m   1461\u001B[0m     compiler_fn \u001B[38;5;241m=\u001B[39m WrapperBackend(compiler_fn)\n\u001B[0;32m-> 1462\u001B[0m compiled_fn \u001B[38;5;241m=\u001B[39m compiler_fn(gm, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexample_inputs())\n\u001B[1;32m   1463\u001B[0m _step_logger()(logging\u001B[38;5;241m.\u001B[39mINFO, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdone compiler function \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1464\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(compiled_fn), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompiler_fn did not return callable\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:130\u001B[0m, in \u001B[0;36mWrapBackendDebug.__call__\u001B[0;34m(self, gm, example_inputs, **kwargs)\u001B[0m\n\u001B[1;32m    128\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m    129\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 130\u001B[0m     compiled_gm \u001B[38;5;241m=\u001B[39m compiler_fn(gm, example_inputs)\n\u001B[1;32m    132\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m compiled_gm\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/__init__.py:2340\u001B[0m, in \u001B[0;36m_TorchCompileInductorWrapper.__call__\u001B[0;34m(self, model_, inputs_)\u001B[0m\n\u001B[1;32m   2337\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, model_, inputs_):\n\u001B[1;32m   2338\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_inductor\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompile_fx\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m compile_fx\n\u001B[0;32m-> 2340\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m compile_fx(model_, inputs_, config_patches\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig)\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1863\u001B[0m, in \u001B[0;36mcompile_fx\u001B[0;34m(model_, example_inputs_, inner_compile, config_patches, decompositions)\u001B[0m\n\u001B[1;32m   1856\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m inference_compiler(unlifted_gm, example_inputs_)\n\u001B[1;32m   1858\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m V\u001B[38;5;241m.\u001B[39mset_fake_mode(fake_mode), torch\u001B[38;5;241m.\u001B[39m_guards\u001B[38;5;241m.\u001B[39mtracing(\n\u001B[1;32m   1859\u001B[0m     tracing_context\n\u001B[1;32m   1860\u001B[0m ), compiled_autograd\u001B[38;5;241m.\u001B[39m_disable(), functorch_config\u001B[38;5;241m.\u001B[39mpatch(\n\u001B[1;32m   1861\u001B[0m     unlift_effect_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1862\u001B[0m ):\n\u001B[0;32m-> 1863\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m aot_autograd(\n\u001B[1;32m   1864\u001B[0m         fw_compiler\u001B[38;5;241m=\u001B[39mfw_compiler,\n\u001B[1;32m   1865\u001B[0m         bw_compiler\u001B[38;5;241m=\u001B[39mbw_compiler,\n\u001B[1;32m   1866\u001B[0m         inference_compiler\u001B[38;5;241m=\u001B[39minference_compiler,\n\u001B[1;32m   1867\u001B[0m         decompositions\u001B[38;5;241m=\u001B[39mdecompositions,\n\u001B[1;32m   1868\u001B[0m         partition_fn\u001B[38;5;241m=\u001B[39mpartition_fn,\n\u001B[1;32m   1869\u001B[0m         keep_inference_input_mutations\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m   1870\u001B[0m         cudagraphs\u001B[38;5;241m=\u001B[39mcudagraphs,\n\u001B[1;32m   1871\u001B[0m     )(model_, example_inputs_)\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/backends/common.py:83\u001B[0m, in \u001B[0;36mAotAutograd.__call__\u001B[0;34m(self, gm, example_inputs, **kwargs)\u001B[0m\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     81\u001B[0m     \u001B[38;5;66;03m# NB: NOT cloned!\u001B[39;00m\n\u001B[1;32m     82\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m enable_aot_logging(), patch_config:\n\u001B[0;32m---> 83\u001B[0m         cg \u001B[38;5;241m=\u001B[39m aot_module_simplified(gm, example_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwargs)\n\u001B[1;32m     84\u001B[0m         counters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maot_autograd\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mok\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     85\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m disable(cg)\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:1155\u001B[0m, in \u001B[0;36maot_module_simplified\u001B[0;34m(mod, args, fw_compiler, bw_compiler, partition_fn, decompositions, keep_inference_input_mutations, inference_compiler, cudagraphs)\u001B[0m\n\u001B[1;32m   1145\u001B[0m     compiled_fn \u001B[38;5;241m=\u001B[39m AOTAutogradCache\u001B[38;5;241m.\u001B[39mload(\n\u001B[1;32m   1146\u001B[0m         dispatch_and_compile,\n\u001B[1;32m   1147\u001B[0m         mod,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1152\u001B[0m         remote,\n\u001B[1;32m   1153\u001B[0m     )\n\u001B[1;32m   1154\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1155\u001B[0m     compiled_fn \u001B[38;5;241m=\u001B[39m dispatch_and_compile()\n\u001B[1;32m   1157\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mod, torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mGmWrapper):\n\u001B[1;32m   1158\u001B[0m     \u001B[38;5;66;03m# This function is called by the flatten_graph_inputs wrapper, which boxes\u001B[39;00m\n\u001B[1;32m   1159\u001B[0m     \u001B[38;5;66;03m# the inputs so that they can be freed before the end of this scope.\u001B[39;00m\n\u001B[1;32m   1160\u001B[0m     \u001B[38;5;66;03m# For overhead reasons, this is not the default wrapper, see comment:\u001B[39;00m\n\u001B[1;32m   1161\u001B[0m     \u001B[38;5;66;03m# https://github.com/pytorch/pytorch/pull/122535/files#r1560096481\u001B[39;00m\n\u001B[1;32m   1162\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mboxed_forward\u001B[39m(runtime_args: List[Any]):\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:1131\u001B[0m, in \u001B[0;36maot_module_simplified.<locals>.dispatch_and_compile\u001B[0;34m()\u001B[0m\n\u001B[1;32m   1129\u001B[0m functional_call \u001B[38;5;241m=\u001B[39m create_functional_call(mod, params_spec, params_len)\n\u001B[1;32m   1130\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m compiled_autograd\u001B[38;5;241m.\u001B[39m_disable():\n\u001B[0;32m-> 1131\u001B[0m     compiled_fn, _ \u001B[38;5;241m=\u001B[39m create_aot_dispatcher_function(\n\u001B[1;32m   1132\u001B[0m         functional_call,\n\u001B[1;32m   1133\u001B[0m         fake_flat_args,\n\u001B[1;32m   1134\u001B[0m         aot_config,\n\u001B[1;32m   1135\u001B[0m         fake_mode,\n\u001B[1;32m   1136\u001B[0m         shape_env,\n\u001B[1;32m   1137\u001B[0m     )\n\u001B[1;32m   1138\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m compiled_fn\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:580\u001B[0m, in \u001B[0;36mcreate_aot_dispatcher_function\u001B[0;34m(flat_fn, fake_flat_args, aot_config, fake_mode, shape_env)\u001B[0m\n\u001B[1;32m    572\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcreate_aot_dispatcher_function\u001B[39m(\n\u001B[1;32m    573\u001B[0m     flat_fn,\n\u001B[1;32m    574\u001B[0m     fake_flat_args: FakifiedFlatArgs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    577\u001B[0m     shape_env: Optional[ShapeEnv],\n\u001B[1;32m    578\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Callable, ViewAndMutationMeta]:\n\u001B[1;32m    579\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m dynamo_timed(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcreate_aot_dispatcher_function\u001B[39m\u001B[38;5;124m\"\u001B[39m, log_pt2_compile_event\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m--> 580\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _create_aot_dispatcher_function(\n\u001B[1;32m    581\u001B[0m             flat_fn, fake_flat_args, aot_config, fake_mode, shape_env\n\u001B[1;32m    582\u001B[0m         )\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:830\u001B[0m, in \u001B[0;36m_create_aot_dispatcher_function\u001B[0;34m(flat_fn, fake_flat_args, aot_config, fake_mode, shape_env)\u001B[0m\n\u001B[1;32m    826\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m aot_dispatch_base\n\u001B[1;32m    828\u001B[0m compiler_fn \u001B[38;5;241m=\u001B[39m choose_dispatcher(needs_autograd, aot_config)\n\u001B[0;32m--> 830\u001B[0m compiled_fn, fw_metadata \u001B[38;5;241m=\u001B[39m compiler_fn(\n\u001B[1;32m    831\u001B[0m     flat_fn,\n\u001B[1;32m    832\u001B[0m     _dup_fake_script_obj(fake_flat_args),\n\u001B[1;32m    833\u001B[0m     aot_config,\n\u001B[1;32m    834\u001B[0m     fw_metadata\u001B[38;5;241m=\u001B[39mfw_metadata,\n\u001B[1;32m    835\u001B[0m )\n\u001B[1;32m    836\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m compiled_fn, fw_metadata\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:203\u001B[0m, in \u001B[0;36maot_dispatch_base\u001B[0;34m(flat_fn, flat_args, aot_config, fw_metadata)\u001B[0m\n\u001B[1;32m    201\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(fw_module, GraphModule)\n\u001B[1;32m    202\u001B[0m         tensorify_python_scalars(fw_module, fake_mode\u001B[38;5;241m.\u001B[39mshape_env, fake_mode)\n\u001B[0;32m--> 203\u001B[0m     compiled_fw \u001B[38;5;241m=\u001B[39m compiler(fw_module, updated_flat_args)\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fakified_out_wrapper\u001B[38;5;241m.\u001B[39mneeds_post_compile:\n\u001B[1;32m    206\u001B[0m     fakified_out_wrapper\u001B[38;5;241m.\u001B[39mset_fwd_output_strides(fwd_output_strides)\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:489\u001B[0m, in \u001B[0;36mSerializableAOTDispatchCompiler.__call__\u001B[0;34m(self, gm, example_inputs)\u001B[0m\n\u001B[1;32m    484\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\n\u001B[1;32m    485\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    486\u001B[0m     gm: torch\u001B[38;5;241m.\u001B[39mfx\u001B[38;5;241m.\u001B[39mGraphModule,\n\u001B[1;32m    487\u001B[0m     example_inputs: Sequence[InputType],\n\u001B[1;32m    488\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m OutputCode:\n\u001B[0;32m--> 489\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompiler_fn(gm, example_inputs)\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1741\u001B[0m, in \u001B[0;36mcompile_fx.<locals>.fw_compiler_base\u001B[0;34m(gm, example_inputs, is_inference)\u001B[0m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1739\u001B[0m     model_outputs_node\u001B[38;5;241m.\u001B[39mmeta[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser_visible_output_idxs\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m-> 1741\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m inner_compile(\n\u001B[1;32m   1742\u001B[0m     gm,\n\u001B[1;32m   1743\u001B[0m     example_inputs,\n\u001B[1;32m   1744\u001B[0m     static_input_idxs\u001B[38;5;241m=\u001B[39mget_static_input_idxs(fixed),\n\u001B[1;32m   1745\u001B[0m     cudagraphs\u001B[38;5;241m=\u001B[39mcudagraphs,\n\u001B[1;32m   1746\u001B[0m     graph_id\u001B[38;5;241m=\u001B[39mgraph_id,\n\u001B[1;32m   1747\u001B[0m     is_inference\u001B[38;5;241m=\u001B[39mis_inference,\n\u001B[1;32m   1748\u001B[0m     boxed_forward_device_index\u001B[38;5;241m=\u001B[39mforward_device,\n\u001B[1;32m   1749\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:569\u001B[0m, in \u001B[0;36mcompile_fx_inner\u001B[0;34m(gm, example_inputs, **kwargs)\u001B[0m\n\u001B[1;32m    562\u001B[0m stack\u001B[38;5;241m.\u001B[39menter_context(DebugContext())\n\u001B[1;32m    564\u001B[0m get_chromium_event_logger()\u001B[38;5;241m.\u001B[39madd_event_data(\n\u001B[1;32m    565\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minductor_compile\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    566\u001B[0m     is_backward\u001B[38;5;241m=\u001B[39mkwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_backward\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    567\u001B[0m )\n\u001B[0;32m--> 569\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m wrap_compiler_debug(_compile_fx_inner, compiler_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minductor\u001B[39m\u001B[38;5;124m\"\u001B[39m)(\n\u001B[1;32m    570\u001B[0m     gm,\n\u001B[1;32m    571\u001B[0m     example_inputs,\n\u001B[1;32m    572\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    573\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:102\u001B[0m, in \u001B[0;36mwrap_compiler_debug.<locals>.debug_wrapper\u001B[0;34m(gm, example_inputs, **kwargs)\u001B[0m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m config\u001B[38;5;241m.\u001B[39mrepro_after \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdynamo\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maot\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    100\u001B[0m     \u001B[38;5;66;03m# Call the compiler_fn - which is either aot_autograd or inductor\u001B[39;00m\n\u001B[1;32m    101\u001B[0m     \u001B[38;5;66;03m# with fake inputs\u001B[39;00m\n\u001B[0;32m--> 102\u001B[0m     inner_compiled_fn \u001B[38;5;241m=\u001B[39m compiler_fn(gm, example_inputs)\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    104\u001B[0m     \u001B[38;5;66;03m# TODO: Failures here are troublesome because no real inputs,\u001B[39;00m\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;66;03m# need a different serialization strategy\u001B[39;00m\n\u001B[1;32m    106\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mrepro_after \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maot\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:685\u001B[0m, in \u001B[0;36m_compile_fx_inner\u001B[0;34m(gm, example_inputs, **graph_kwargs)\u001B[0m\n\u001B[1;32m    683\u001B[0m TritonBundler\u001B[38;5;241m.\u001B[39mbegin_compile()\n\u001B[1;32m    684\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 685\u001B[0m     mb_compiled_graph \u001B[38;5;241m=\u001B[39m fx_codegen_and_compile(\n\u001B[1;32m    686\u001B[0m         gm, example_inputs, inputs_to_check, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mgraph_kwargs\n\u001B[1;32m    687\u001B[0m     )\n\u001B[1;32m    688\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m mb_compiled_graph \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    689\u001B[0m     mb_compiled_graph\u001B[38;5;241m.\u001B[39m_time_taken_ns \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime_ns() \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1129\u001B[0m, in \u001B[0;36mfx_codegen_and_compile\u001B[0;34m(gm, example_inputs, inputs_to_check, **graph_kwargs)\u001B[0m\n\u001B[1;32m   1119\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mfx_codegen_and_compile\u001B[39m(\n\u001B[1;32m   1120\u001B[0m     gm: GraphModule,\n\u001B[1;32m   1121\u001B[0m     example_inputs: Sequence[InputType],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1125\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mgraph_kwargs: Unpack[_CompileFxKwargs],\n\u001B[1;32m   1126\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m OutputCode:\n\u001B[1;32m   1127\u001B[0m     scheme: FxCompile \u001B[38;5;241m=\u001B[39m _InProcessFxCompile()\n\u001B[0;32m-> 1129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m scheme\u001B[38;5;241m.\u001B[39mcodegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1044\u001B[0m, in \u001B[0;36m_InProcessFxCompile.codegen_and_compile\u001B[0;34m(self, gm, example_inputs, inputs_to_check, graph_kwargs)\u001B[0m\n\u001B[1;32m   1036\u001B[0m             compiled_fn \u001B[38;5;241m=\u001B[39m AotCodeCompiler\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[1;32m   1037\u001B[0m                 graph,\n\u001B[1;32m   1038\u001B[0m                 code,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1041\u001B[0m                 additional_files\u001B[38;5;241m=\u001B[39madditional_files,\n\u001B[1;32m   1042\u001B[0m             )\n\u001B[1;32m   1043\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1044\u001B[0m         compiled_fn \u001B[38;5;241m=\u001B[39m graph\u001B[38;5;241m.\u001B[39mcompile_to_module()\u001B[38;5;241m.\u001B[39mcall\n\u001B[1;32m   1046\u001B[0m num_bytes, nodes_num_elem, node_runtimes \u001B[38;5;241m=\u001B[39m graph\u001B[38;5;241m.\u001B[39mcount_bytes()\n\u001B[1;32m   1047\u001B[0m metrics\u001B[38;5;241m.\u001B[39mnum_bytes_accessed \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m num_bytes\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/graph.py:2027\u001B[0m, in \u001B[0;36mGraphLowering.compile_to_module\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2020\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcompile_to_module\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ModuleType:\n\u001B[1;32m   2021\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m dynamo_timed(\n\u001B[1;32m   2022\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGraphLowering.compile_to_module\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   2023\u001B[0m         phase_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode_gen\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   2024\u001B[0m         log_pt2_compile_event\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m   2025\u001B[0m         dynamo_compile_column_us\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minductor_code_gen_cumulative_compile_time_us\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   2026\u001B[0m     ):\n\u001B[0;32m-> 2027\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compile_to_module()\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/graph.py:2033\u001B[0m, in \u001B[0;36mGraphLowering._compile_to_module\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2029\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_compile_to_module\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ModuleType:\n\u001B[1;32m   2030\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcodecache\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PyCodeCache\n\u001B[1;32m   2032\u001B[0m     code, linemap \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m-> 2033\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcodegen_with_cpp_wrapper() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcpp_wrapper \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcodegen()\n\u001B[1;32m   2034\u001B[0m     )\n\u001B[1;32m   2035\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mtriton\u001B[38;5;241m.\u001B[39mautotune_at_compile_time:\n\u001B[1;32m   2036\u001B[0m         tuning_code \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   2037\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m   2038\u001B[0m             \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCompile-time auto-tuning block: \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2041\u001B[0m             \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m   2042\u001B[0m         )\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/graph.py:1968\u001B[0m, in \u001B[0;36mGraphLowering.codegen\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1965\u001B[0m V\u001B[38;5;241m.\u001B[39mdebug\u001B[38;5;241m.\u001B[39mdraw_orig_fx_graph(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morig_gm, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscheduler\u001B[38;5;241m.\u001B[39mnodes)\n\u001B[1;32m   1967\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrapper_code\u001B[38;5;241m.\u001B[39mpush_codegened_graph(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m-> 1968\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscheduler\u001B[38;5;241m.\u001B[39mcodegen()\n\u001B[1;32m   1970\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\n\u001B[1;32m   1971\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFinished codegen for all nodes. The list of kernel names available: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1972\u001B[0m     V\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mall_codegen_kernel_names,\n\u001B[1;32m   1973\u001B[0m )\n\u001B[1;32m   1975\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrapper_code\u001B[38;5;241m.\u001B[39mgenerate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_inference)\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/scheduler.py:3477\u001B[0m, in \u001B[0;36mScheduler.codegen\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   3475\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcodegen\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3476\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m dynamo_timed(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mScheduler.codegen\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 3477\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_codegen()\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/scheduler.py:3554\u001B[0m, in \u001B[0;36mScheduler._codegen\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   3552\u001B[0m     backend\u001B[38;5;241m.\u001B[39mcodegen_combo_kernel(node)\n\u001B[1;32m   3553\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(node, (FusedSchedulerNode, SchedulerNode)):\n\u001B[0;32m-> 3554\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_backend(device)\u001B[38;5;241m.\u001B[39mcodegen_node(node)\n\u001B[1;32m   3555\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3556\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(node, NopKernelSchedulerNode)\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:4777\u001B[0m, in \u001B[0;36mCppScheduling.codegen_node\u001B[0;34m(self, node)\u001B[0m\n\u001B[1;32m   4774\u001B[0m kernel_group \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel_group\n\u001B[1;32m   4776\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(node, OuterLoopFusedSchedulerNode):\n\u001B[0;32m-> 4777\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcodegen_outer_loop_node(node)\n\u001B[1;32m   4778\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   4779\u001B[0m     nodes: List[SchedulerNode] \u001B[38;5;241m=\u001B[39m node\u001B[38;5;241m.\u001B[39mget_nodes()  \u001B[38;5;66;03m# type: ignore[assignment]\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:4751\u001B[0m, in \u001B[0;36mCppScheduling.codegen_outer_loop_node\u001B[0;34m(self, node)\u001B[0m\n\u001B[1;32m   4744\u001B[0m         kernel_group\u001B[38;5;241m.\u001B[39mfinalize_kernel(\n\u001B[1;32m   4745\u001B[0m             outer_fusion_cpp_kernel_proxy,\n\u001B[1;32m   4746\u001B[0m             [_node \u001B[38;5;28;01mfor\u001B[39;00m _nodes \u001B[38;5;129;01min\u001B[39;00m nodes_list \u001B[38;5;28;01mfor\u001B[39;00m _node \u001B[38;5;129;01min\u001B[39;00m _nodes],\n\u001B[1;32m   4747\u001B[0m         )\n\u001B[1;32m   4749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m-> 4751\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m try_outer_loop_fusion_with_local_buf(node):\n\u001B[1;32m   4752\u001B[0m     \u001B[38;5;66;03m# Reset generated_cpp_vec_kernel_count to codegen again\u001B[39;00m\n\u001B[1;32m   4753\u001B[0m     metrics\u001B[38;5;241m.\u001B[39mgenerated_cpp_vec_kernel_count \u001B[38;5;241m=\u001B[39m generated_cpp_vec_kernel_count\n\u001B[1;32m   4754\u001B[0m     cpp_kernel_proxy_list\u001B[38;5;241m.\u001B[39mclear()\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:4726\u001B[0m, in \u001B[0;36mCppScheduling.codegen_outer_loop_node.<locals>.try_outer_loop_fusion_with_local_buf\u001B[0;34m(node)\u001B[0m\n\u001B[1;32m   4724\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _node \u001B[38;5;129;01min\u001B[39;00m node\u001B[38;5;241m.\u001B[39mget_outer_nodes():\n\u001B[1;32m   4725\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(_node, (FusedSchedulerNode, SchedulerNode))\n\u001B[0;32m-> 4726\u001B[0m     cpp_kernel_proxy \u001B[38;5;241m=\u001B[39m CppKernelProxy(kernel_group)\n\u001B[1;32m   4727\u001B[0m     cpp_kernel_proxy\u001B[38;5;241m.\u001B[39mcodegen_nodes(_node\u001B[38;5;241m.\u001B[39mget_nodes())  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m   4728\u001B[0m     cpp_kernel_proxy_list\u001B[38;5;241m.\u001B[39mappend(cpp_kernel_proxy)\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3632\u001B[0m, in \u001B[0;36mCppKernelProxy.__init__\u001B[0;34m(self, kernel_group)\u001B[0m\n\u001B[1;32m   3630\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloop_nest \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   3631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcall_ranges \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 3632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpicked_vec_isa: cpu_vec_isa\u001B[38;5;241m.\u001B[39mVecISA \u001B[38;5;241m=\u001B[39m cpu_vec_isa\u001B[38;5;241m.\u001B[39mpick_vec_isa()\n\u001B[1;32m   3633\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernels: List[CppKernel] \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/cpu_vec_isa.py:414\u001B[0m, in \u001B[0;36mpick_vec_isa\u001B[0;34m()\u001B[0m\n\u001B[1;32m    411\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mis_fbcode() \u001B[38;5;129;01mand\u001B[39;00m (platform\u001B[38;5;241m.\u001B[39mmachine() \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx86_64\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAMD64\u001B[39m\u001B[38;5;124m\"\u001B[39m]):\n\u001B[1;32m    412\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m VecAVX2()\n\u001B[0;32m--> 414\u001B[0m _valid_vec_isa_list: List[VecISA] \u001B[38;5;241m=\u001B[39m valid_vec_isa_list()\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _valid_vec_isa_list:\n\u001B[1;32m    416\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m invalid_vec_isa\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/cpu_vec_isa.py:401\u001B[0m, in \u001B[0;36mvalid_vec_isa_list\u001B[0;34m()\u001B[0m\n\u001B[1;32m    397\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    398\u001B[0m \u001B[38;5;124;03m    arch value is x86_64 on Linux, and the value is AMD64 on Windows.\u001B[39;00m\n\u001B[1;32m    399\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m    400\u001B[0m     _cpu_supported_x86_isa \u001B[38;5;241m=\u001B[39m x86_isa_checker()\n\u001B[0;32m--> 401\u001B[0m     isa_list\u001B[38;5;241m.\u001B[39mextend(\n\u001B[1;32m    402\u001B[0m         isa\n\u001B[1;32m    403\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m isa \u001B[38;5;129;01min\u001B[39;00m supported_vec_isa_list\n\u001B[1;32m    404\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mall\u001B[39m(flag \u001B[38;5;129;01min\u001B[39;00m _cpu_supported_x86_isa \u001B[38;5;28;01mfor\u001B[39;00m flag \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(isa)\u001B[38;5;241m.\u001B[39msplit()) \u001B[38;5;129;01mand\u001B[39;00m isa\n\u001B[1;32m    405\u001B[0m     )\n\u001B[1;32m    407\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m isa_list\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/cpu_vec_isa.py:404\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    397\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    398\u001B[0m \u001B[38;5;124;03m    arch value is x86_64 on Linux, and the value is AMD64 on Windows.\u001B[39;00m\n\u001B[1;32m    399\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m    400\u001B[0m     _cpu_supported_x86_isa \u001B[38;5;241m=\u001B[39m x86_isa_checker()\n\u001B[1;32m    401\u001B[0m     isa_list\u001B[38;5;241m.\u001B[39mextend(\n\u001B[1;32m    402\u001B[0m         isa\n\u001B[1;32m    403\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m isa \u001B[38;5;129;01min\u001B[39;00m supported_vec_isa_list\n\u001B[0;32m--> 404\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mall\u001B[39m(flag \u001B[38;5;129;01min\u001B[39;00m _cpu_supported_x86_isa \u001B[38;5;28;01mfor\u001B[39;00m flag \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(isa)\u001B[38;5;241m.\u001B[39msplit()) \u001B[38;5;129;01mand\u001B[39;00m isa\n\u001B[1;32m    405\u001B[0m     )\n\u001B[1;32m    407\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m isa_list\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/cpu_vec_isa.py:142\u001B[0m, in \u001B[0;36mVecISA.__bool__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__bool__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n\u001B[0;32m--> 142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__bool__impl(config\u001B[38;5;241m.\u001B[39mcpp\u001B[38;5;241m.\u001B[39mvec_isa_ok)\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/cpu_vec_isa.py:152\u001B[0m, in \u001B[0;36mVecISA.__bool__impl\u001B[0;34m(self, vec_isa_ok)\u001B[0m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mis_fbcode():\n\u001B[1;32m    150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 152\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_build(VecISA\u001B[38;5;241m.\u001B[39m_avx_code)\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/cpu_vec_isa.py:102\u001B[0m, in \u001B[0;36mVecISA.check_build\u001B[0;34m(self, code)\u001B[0m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_inductor\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcodecache\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_lock_dir, LOCK_TIMEOUT, write\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_inductor\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcpp_builder\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     94\u001B[0m     CppBuilder,\n\u001B[1;32m     95\u001B[0m     CppTorchOptions,\n\u001B[1;32m     96\u001B[0m     normalize_path_separator,\n\u001B[1;32m     97\u001B[0m )\n\u001B[1;32m     99\u001B[0m key, input_path \u001B[38;5;241m=\u001B[39m write(\n\u001B[1;32m    100\u001B[0m     code,\n\u001B[1;32m    101\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpp\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m--> 102\u001B[0m     extra\u001B[38;5;241m=\u001B[39m_get_isa_dry_compile_fingerprint(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_arch_flags),\n\u001B[1;32m    103\u001B[0m )\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfilelock\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FileLock\n\u001B[1;32m    106\u001B[0m lock_dir \u001B[38;5;241m=\u001B[39m get_lock_dir()\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/cpu_vec_isa.py:28\u001B[0m, in \u001B[0;36m_get_isa_dry_compile_fingerprint\u001B[0;34m(isa_flags)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_get_isa_dry_compile_fingerprint\u001B[39m(isa_flags: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;66;03m# ISA dry compile will cost about 1 sec time each startup time.\u001B[39;00m\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;66;03m# Please check the issue: https://github.com/pytorch/pytorch/issues/100378\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;66;03m# and generated them to output binary hash path.\u001B[39;00m\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;66;03m# It would optimize and skip compile existing binary.\u001B[39;00m\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_inductor\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcpp_builder\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_compiler_version_info, get_cpp_compiler\n\u001B[0;32m---> 28\u001B[0m     compiler_info \u001B[38;5;241m=\u001B[39m get_compiler_version_info(get_cpp_compiler())\n\u001B[1;32m     29\u001B[0m     torch_version \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39m__version__\n\u001B[1;32m     30\u001B[0m     fingerprint \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcompiler_info\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00misa_flags\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch_version\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:152\u001B[0m, in \u001B[0;36mget_cpp_compiler\u001B[0;34m()\u001B[0m\n\u001B[1;32m    150\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    151\u001B[0m         search \u001B[38;5;241m=\u001B[39m (config\u001B[38;5;241m.\u001B[39mcpp\u001B[38;5;241m.\u001B[39mcxx,)\n\u001B[0;32m--> 152\u001B[0m     compiler \u001B[38;5;241m=\u001B[39m cpp_compiler_search(search)\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m compiler\n",
      "File \u001B[0;32m~/miniconda3/envs/IMPACT/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:94\u001B[0m, in \u001B[0;36mcpp_compiler_search\u001B[0;34m(search)\u001B[0m\n\u001B[1;32m     92\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (subprocess\u001B[38;5;241m.\u001B[39mSubprocessError, \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m, \u001B[38;5;167;01mImportError\u001B[39;00m):\n\u001B[1;32m     93\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m---> 94\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\u001B[38;5;241m.\u001B[39mInvalidCxxCompiler\n",
      "\u001B[0;31mBackendCompilerFailed\u001B[0m: backend='inductor' raised:\nInvalidCxxCompiler: No working C++ compiler found in torch._inductor.config.cpp.cxx: (None, 'g++')\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1003d70-beb1-4170-9993-ee62dcff200a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(S.CDM.model.R!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b482e14-d9dc-4926-b6e0-75cd51ba5998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
